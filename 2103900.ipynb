{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 飞桨常规赛：PALM病理性近视预测6月第4名方案\n",
    "\n",
    "此方案来自大佬的方案，并在这基础上做了一些新的尝试。基线地址：\n",
    "\n",
    "https://aistudio.baidu.com/aistudio/projectdetail/1938000?channelType=0&channel=0\n",
    "\n",
    "本人有幸获得第4名\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/4d44b5330025433b875040f9320ce5f379f5621e6bac4f089b01c7bac9937cf5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 常规赛：PALM眼底彩照视盘探测与分割基线方案\n",
    "\n",
    "**赛题简述**\n",
    "\t\n",
    "    PALM眼底视盘检测与分割常规赛的重点是研究和发展与患者眼底照片结构分割相关的算法。该常规赛的目标是评估和比较在一个常见的视网膜眼底图像数据集上分割视盘的自动算法。该任务目的是对眼底图像的视盘进行检测，若存在视盘结构，需从眼底图像中分割出视盘区域；若无视盘结构，分割结果直接置全背景。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/938ab4fac88e44969e61f8f10181ca1366c53fbc3d6147ff80487b03c964543e)\n",
    "\n",
    "\n",
    "**数据基本标签**\n",
    "\n",
    "\t标签为 0 代表视盘（黑色区域）；标签为 255 代表其他（白色区域）。\n",
    "    \n",
    "\n",
    "**训练数据集**\n",
    "\n",
    "文件名称：Train\n",
    "\n",
    "Train文件夹里有fundus_images文件夹和Disc_Masks文件夹。\n",
    "\n",
    "* fundus_images文件夹内包含800张眼底彩照，分辨率为1444×1444，或2124×2056。命名形如H0001.jpg、N0001.jpg、P0001.jpg和V0001.jpg。\n",
    "\n",
    "* Disc_Masks文件夹内包含fundus_images里眼底彩照的视盘分割金标准，大小与对应的眼底彩照一致。命名前缀和对应的fundus_images文件夹里的图像命名一致，后缀为bmp。\n",
    "\n",
    "**测试数据集**\n",
    "\n",
    "文件名称：PALM-Testing400-Images\n",
    "\n",
    "* 包含400张眼底彩照，命名形如T0001.jpg。\n",
    "\n",
    "评价指标为：0.4 X F1分数 + 0.6 X Dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 一、基线方案内容\n",
    "\n",
    "* 解压数据与数据划分\n",
    "\n",
    "\t-- # 解压数据集\n",
    "    \n",
    "\t-- !unzip -oq /home/aistudio/data/data85136/常规赛：PALM眼底彩照视盘探测与分割.zip -d PaddleSeg/data\n",
    "    \n",
    "   -- # 划分数据\n",
    "   \n",
    "\t-- !python utils/dataset_splited.py\n",
    "\n",
    "* 数据标签预处理\n",
    "\n",
    "   -- # 转换标签\n",
    "   \n",
    "   -- !python utils/dataset_pretrans.py\n",
    "\n",
    "\t* 原分类为1分类问题，为了问题研究的充分性和更大程度上利用多分类间的类别竞争对分类结构有一个更好的指导\n",
    "   \n",
    "   * 二分类问题描述，原标签为0不变，将255无效值转换为1值\n",
    "   \n",
    "   * 后期提交前会后处理，消去1值，换回赛题需要的255值\n",
    "   \n",
    "* 利用PaddleSeg套件加速赛题开发与测试: 可参考套件config中的yml，结合动态图API进行快速高效的实验开发\n",
    "\n",
    "* 实现训练流程\n",
    "\n",
    "* 实现预测流程\n",
    "\n",
    "* 完成提交结果 -- 基线方案为0.92431的得分(iters:2400)，可从**训练迭代次数**、**损失函数**、**模型**入手\n",
    "\t\n",
    "   -- # 提交结果后处理\n",
    "   \n",
    "\t-- utils/post_process.py\n",
    "\n",
    "**部分训练参数**\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/19c1febc87ec4fd78bb5b4a1966389c0979588525df44379885e5543c41d363c)\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/d8ff821a46ab43df8e13fda1d2e5752bd4a54eeb3ae643dbad0288ff41f0c6cd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **二、本次方案**\n",
    "\n",
    "在基线的基础上，尝试不同的学习率lr+不同图片尺寸，使用了680x680,800x800（发现800x800效果更好），并且在原有的数据增强上增加了垂直翻转，本想加入更多的数据增强，例如随机旋转、对比度等，但是会一直报错，具体原因我还没弄明白，大家可以多尝试传统的数据增强方式，这是稳定的涨分点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "                                                                                                                                                                                                                                                                            # 解压PaddleSeg压缩包\r\n",
    "!unzip -oq data/data88946/PaddleSeg.zip -d /home/aistudio/\r\n",
    "# 修改文件名\r\n",
    "!mv PaddleSeg-release-v2.0 PaddleSeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "上一步mv，可以将PaddleSeg加压后的文件目录改成PaddleSeg\n",
    "\n",
    "> PaddleSeg下载至github的release2.0版本，为了方便大家使用，已添加在了数据集中供大家使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 解压数据集到PaddleSeg目录下的data文件夹\r\n",
    "!unzip -oq /home/aistudio/data/data96154/常规赛：PALM眼底彩照视盘探测与分割.zip -d PaddleSeg/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PaddleSeg/data/常规赛：PALM眼底彩照视盘探测与分割\r\n",
      "├── PALM-Testing400-Images\r\n",
      "└── Train\r\n",
      "    ├── Disc_Masks\r\n",
      "    └── fundus_image\r\n",
      "\r\n",
      "4 directories\r\n"
     ]
    }
   ],
   "source": [
    "# 查看数据集文件的树形结构\r\n",
    "!tree -d PaddleSeg/data/常规赛：PALM眼底彩照视盘探测与分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 二、比赛数据集情况\n",
    "PALM-Testing400-Images : 测试数据集文件夹\n",
    "\n",
    "Train : 训练数据集文件夹\n",
    "\n",
    "* Disc_Masks   ; 标注图片\n",
    "* fundus_image  : 原始图片\n",
    "\n",
    "> 注意没有验证数据集，这里提供一个简单的划分程序，划分比例为0.9（原为0.7）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "通过PIL的Image读取图片查看以下原数据与Label标注情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\r\n",
    "\r\n",
    "# 读取图片\r\n",
    "png_img = Image.open('PaddleSeg/data/常规赛：PALM眼底彩照视盘探测与分割/Train/fundus_image/H0003.jpg')\r\n",
    "png_img  # 展示图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.BmpImagePlugin.BmpImageFile image mode=L size=1444x1444 at 0x7F75281174D0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bmp_img = Image.open('PaddleSeg/data/常规赛：PALM眼底彩照视盘探测与分割/Train/Disc_Masks/H0003.bmp')\r\n",
    "bmp_img   # 展示图片"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "可以看出，白色部分全是255，黑色为有效标注区域(0值)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 三、划分数据集与数据预处置\n",
    "\n",
    "\n",
    "当前划分比例为0.9——可在`utils`文件夹下的`dataset_splited.py`修改`train_percent`为其它值\n",
    "\n",
    "数据预处置-可在`utils`文件夹下的`dataset_pretrans.py`中查看相关代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio\n",
      "————开始数据清洗划分————\n",
      "The Split Params: train_percent=0.90\n",
      "Image Dir Has Ready!\n",
      "Label Dir Has Ready!\n",
      "Processing Train Split: 100%|█████████████████| 720/720 [00:53<00:00, 13.38it/s]\n",
      "Processing Val Split: 100%|█████████████████████| 80/80 [00:07<00:00, 10.51it/s]\n",
      "Processing Test Split: 100%|██████████████████| 400/400 [00:05<00:00, 74.71it/s]\n",
      "完成数据集划分：\n",
      "- 数据根目录: PaddleSeg/data\n",
      "\t - 子目录: Image: 存放真实图片\n",
      "\t\t - to_train: 训练用 , lens:720\n",
      "\t\t - to_val: 验证用 , lens:80\n",
      "\t\t - to_test: 测试用(提交预测) , lens:400\n",
      "\t - 子目录: Label: 存放标注图片\n",
      "\t\t - to_train: 训练用 , lens:720\n",
      "\t\t - to_val: 验证用 , lens:80\n",
      "\t\t - to_test: 测试用(保存提交预测) , lens:0\n",
      "————开始数据预处理转换————\n",
      "转换说明:\n",
      "\t 1. 默认标签为255与0，为了训练方便，将255转换为1，变成2分类问题\n",
      "\t 2. 新标签0与1，预测结束进行后处理即可得到赛题需要的结果\n",
      "100%|█████████████████████████████████████████| 800/800 [00:21<00:00, 36.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# 保证路径为初始路径\r\n",
    "%cd /home/aistudio\r\n",
    "\r\n",
    "# 划分数据\r\n",
    "!python utils/dataset_splited.py\r\n",
    "\r\n",
    "# 转换标签--预处置\r\n",
    "!python utils/dataset_pretrans.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "移除原数据，减小项目空间，减少下一次进入和退出保存时花的时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 移除’常规赛：PALM眼底彩照视盘探测与分割‘文件夹\r\n",
    "!rm -rf PaddleSeg/data/常规赛：PALM眼底彩照视盘探测与分割\r\n",
    "!rm -rf PaddleSeg/data/__MACOSX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 四、下载依赖项\n",
    "\n",
    "> 平台可以不用下载，但是如果在本地可能需要执行这一步"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/PaddleSeg\n",
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Requirement already satisfied: pre-commit in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r requirements.txt (line 1)) (1.21.0)\n",
      "Requirement already satisfied: yapf==0.26.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (0.26.0)\n",
      "Requirement already satisfied: flake8 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.8.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (5.1.2)\n",
      "Requirement already satisfied: visualdl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r requirements.txt (line 5)) (2.1.1)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r requirements.txt (line 6)) (4.1.1.26)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r requirements.txt (line 7)) (4.36.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r requirements.txt (line 8)) (3.0.12)\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r requirements.txt (line 9)) (1.6.3)\n",
      "Requirement already satisfied: prettytable in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r requirements.txt (line 10)) (0.7.2)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->-r requirements.txt (line 1)) (1.3.4)\n",
      "Requirement already satisfied: aspy.yaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->-r requirements.txt (line 1)) (2.0.1)\n",
      "Requirement already satisfied: toml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->-r requirements.txt (line 1)) (0.10.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->-r requirements.txt (line 1)) (0.23)\n",
      "Requirement already satisfied: virtualenv>=15.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->-r requirements.txt (line 1)) (16.7.9)\n",
      "Requirement already satisfied: identify>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->-r requirements.txt (line 1)) (1.4.10)\n",
      "Requirement already satisfied: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->-r requirements.txt (line 1)) (1.15.0)\n",
      "Requirement already satisfied: pyflakes<2.3.0,>=2.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8->-r requirements.txt (line 3)) (2.2.0)\n",
      "Requirement already satisfied: pycodestyle<2.7.0,>=2.6.0a1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8->-r requirements.txt (line 3)) (2.6.0)\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8->-r requirements.txt (line 3)) (0.6.1)\n",
      "Requirement already satisfied: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->-r requirements.txt (line 5)) (0.8.53)\n",
      "Requirement already satisfied: Pillow>=7.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->-r requirements.txt (line 5)) (7.1.2)\n",
      "Requirement already satisfied: flask>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->-r requirements.txt (line 5)) (1.1.1)\n",
      "Requirement already satisfied: protobuf>=3.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->-r requirements.txt (line 5)) (3.14.0)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->-r requirements.txt (line 5)) (2.22.0)\n",
      "Requirement already satisfied: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->-r requirements.txt (line 5)) (1.0.0)\n",
      "Requirement already satisfied: shellcheck-py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->-r requirements.txt (line 5)) (0.7.1.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->-r requirements.txt (line 5)) (1.20.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->pre-commit->-r requirements.txt (line 1)) (0.6.0)\n",
      "Requirement already satisfied: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl>=2.0.0->-r requirements.txt (line 5)) (3.9.9)\n",
      "Requirement already satisfied: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl>=2.0.0->-r requirements.txt (line 5)) (0.18.0)\n",
      "Requirement already satisfied: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.0.0->-r requirements.txt (line 5)) (7.0)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.0.0->-r requirements.txt (line 5)) (1.1.0)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.0.0->-r requirements.txt (line 5)) (0.16.0)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.0.0->-r requirements.txt (line 5)) (2.10.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0->-r requirements.txt (line 5)) (1.25.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0->-r requirements.txt (line 5)) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0->-r requirements.txt (line 5)) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0->-r requirements.txt (line 5)) (2.8)\n",
      "Requirement already satisfied: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0->-r requirements.txt (line 5)) (2.8.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0->-r requirements.txt (line 5)) (2019.3)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->pre-commit->-r requirements.txt (line 1)) (7.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.10.1->flask>=1.1.1->visualdl>=2.0.0->-r requirements.txt (line 5)) (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "# 下载依赖项，保证PaddleSeg正常运行\r\n",
    "%cd PaddleSeg\r\n",
    "%pwd\r\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 五、开始构建比赛模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1.导入需要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'PaddleSeg'\n",
      "/home/aistudio/PaddleSeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:26: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def convert_to_list(value, n, name, dtype=np.int):\n"
     ]
    }
   ],
   "source": [
    "# 当前套件下切换目录到PaddleSeg下，才能使用paddleseg\r\n",
    "%cd PaddleSeg\r\n",
    "%pwd\r\n",
    "\r\n",
    "import paddle                                     # paddle基本框架\r\n",
    "from paddleseg import models as M                 # paddleseg的模型库--对应模型源代码：PaddleSeg/paddleseg/models\r\n",
    "from paddleseg.models import backbones as B       # 分割模型需要的骨干网络--对应模型源代码：PaddleSeg/paddleseg/models/backbones\r\n",
    "from paddleseg.models import losses as L          # 分割模型需要的损失函数--对应模型源代码：PaddleSeg/paddleseg/models/losses\r\n",
    "from paddleseg import transforms as T             # 分割模型需要的数据预处理方法(图像)--对应模型源代码：PaddleSeg/paddleseg/transforms/transforms.py\r\n",
    "from paddleseg.datasets import OpticDiscSeg       # paddleseg对应的数据加载机制--对应模型源代码：PaddleSeg/paddleseg/datasets/optic_disc_seg.py\r\n",
    "from paddleseg.core import train, evaluate, predict  # 训练、评估、预测接口--对应模型源代码：PaddleSeg/paddleseg/core\r\n",
    "\r\n",
    "import os                                         # 必要的文件处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2.创建模型与Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-29 19:56:50 [INFO]\tNo pretrained model to load, ResNet_vd will be trained from scratch.\n"
     ]
    }
   ],
   "source": [
    "# 实例创建一个模型——当前演示基线模型EMANet\r\n",
    "# 其它模型可前往PaddleSeg/paddleseg/models下查看相应的其它.py文件查阅参数，进行配置\r\n",
    "# 也可通过help(M.EMANet)查看类文档描述\r\n",
    "# 必要的，可以参考PaddleSeg/configs中同名模型yml文件配置\r\n",
    "model = M.EMANet(\r\n",
    "                 num_classes=2,                  # 类别数，这里已经转换为2分类问题了\r\n",
    "                 backbone=B.ResNet50_vd(),       # 选用骨干网络--注意骨干网络和backbone_indices的搭配(注意传入的是实例化的对象哦，不要传成类了)\r\n",
    "                 backbone_indices=[2, 3]         # backbone流向分割部分的特征通道index，必要时可以使用[1,], [1, 2], [2, 3], [1, 3], [1, 2, 3]\r\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### EMANet完整参数介绍如下：\n",
    "\n",
    "`source: PaddleSeg/paddleseg/models/emanet.py`\n",
    "\n",
    "```python\n",
    "num_classes,\n",
    "backbone,\n",
    "backbone_indices=(2, 3),       \n",
    "ema_channels=512,            # ema输入通道——backbone输出-->经过ema输入得到ema_channels的通道数\n",
    "gc_channels=256,             # ema输出编码通道(不等于num_classes)\n",
    "num_bases=64,               # 注意力参数个数\n",
    "stage_num=3,                # 编码状态(次数)\n",
    "momentum=0.1,               # 动量--与注意力有关\n",
    "concat_input=True,           # 拼接输入\n",
    "enable_auxiliary_loss=True,     # 组合损失\n",
    "align_corners=False,          # 居中对齐\n",
    "pretrained=None              # 是否加载预处理\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'T' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c83fade61044>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 配置dataset以及相应的transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m train_transforms = [\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomVerticalFlip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m        \u001b[0;31m# 水平翻转\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m800\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m800\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#T.RandomRotation(),#随机旋转\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'T' is not defined"
     ]
    }
   ],
   "source": [
    "# 配置dataset以及相应的transform\r\n",
    "train_transforms = [\r\n",
    "    T.RandomVerticalFlip(),        # 水平翻转\r\n",
    "    T.Resize(target_size=(800, 800)),\r\n",
    "    #T.RandomRotation(),#随机旋转\r\n",
    "    T.Normalize(),\r\n",
    "    T.RandomHorizontalFlip()\r\n",
    "    # T.ResizeStepScaling()#0.5, 2.0, 0.25\r\n",
    "]\r\n",
    "\r\n",
    "# 验证处理可以不添加额外的方式，确定形状即可\r\n",
    "eval_transforms = [\r\n",
    "    T.Resize(target_size=(800, 800)),  # 缩放大小\r\n",
    "    T.Normalize()\r\n",
    "]\r\n",
    "\r\n",
    "# 创建数据集\r\n",
    "train_dataset = OpticDiscSeg(\r\n",
    "    dataset_root='data',             # PaddleSeg/data目录下存在与mode对应的train_list.txt\r\n",
    "    transforms=train_transforms,\r\n",
    "    mode='train'                     # mode不要写错了\r\n",
    ")\r\n",
    "\r\n",
    "eval_dataset = OpticDiscSeg(\r\n",
    "    dataset_root='data',\r\n",
    "    transforms=eval_transforms,\r\n",
    "    mode='val'\r\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.配置学习率与损失计算方式\n",
    "\n",
    "base_lr=0.01改为0.00125\n",
    "\n",
    "使用了Adam优化器但是效果没有Momentum好，可能是我配置优化器其他参数有误，大家也可以去尝试一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_lr = 0.00125    \r\n",
    "# 多项式学习率，由decay_steps决定base_lr到base_lr*0.01的间隔迭代次数\r\n",
    "lr = paddle.optimizer.lr.PolynomialDecay(base_lr, power=0.9, decay_steps=2000, end_lr=base_lr*0.01)\r\n",
    "\r\n",
    "# lr = paddle.optimizer.lr.CosineAnnealingDecay(learning_rate= 0.000001, T_max=int(2*(800*0.9)), verbose=False)\r\n",
    "# opt = paddle.optimizer.Adam(learning_rate=lr, parameters=model.parameters(), weight_decay=paddle.regularizer.L2Decay(1e-7))\r\n",
    "\r\n",
    "# 优化器--可以换用Adam\r\n",
    "# 正则项可以调高一些\r\n",
    "# optimizer = paddle.optimizer.Adam(learning_rate=lr, parameters=model.parameters(), weight_decay=paddle.regularizer.L2Decay(1e-7))\r\n",
    "optimizer = paddle.optimizer.Momentum(lr, parameters=model.parameters(), momentum=0.9, weight_decay=4.0e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# paddleseg支持多损失，所以采用字典的方式配置损失\r\n",
    "losses = {}  # 创建loss字典\r\n",
    "losses['types'] = [L.CrossEntropyLoss(), L.DiceLoss()]  # 将需要的多个损失进行添加\r\n",
    "\r\n",
    "# 每一个损失计算的结果的权重\r\n",
    "# all_loss = losses['types'][0] * losses['coef'][0] + losses['types'][2] * losses['coef'][2]\r\n",
    "losses['coef'] = [4.0, 2.0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* DiceLoss比较符合赛题\n",
    "\n",
    "* CrossEntropyLoss适合多分类损失计算\n",
    "\n",
    "* 如果是相同的损失可以通过: [L.CrossEntropyLoss()] * 2 实现 [L.CrossEntropyLoss(), L.CrossEntropyLoss()]\n",
    "\n",
    "* coef系数值，不是越大越好，控制适当的比例就可以了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4.开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-29 20:02:55 [INFO]\t[TRAIN] epoch=1, iter=10/6000, loss=2.1955, lr=0.001245, batch_cost=3.3545, reader_cost=0.05957, ips=1.1924 samples/sec | ETA 05:34:53\n",
      "2021-06-29 20:03:27 [INFO]\t[TRAIN] epoch=1, iter=20/6000, loss=1.4822, lr=0.001239, batch_cost=3.2887, reader_cost=0.00015, ips=1.2163 samples/sec | ETA 05:27:46\n",
      "2021-06-29 20:04:00 [INFO]\t[TRAIN] epoch=1, iter=30/6000, loss=1.2473, lr=0.001234, batch_cost=3.2860, reader_cost=0.00016, ips=1.2173 samples/sec | ETA 05:26:57\n",
      "2021-06-29 20:04:33 [INFO]\t[TRAIN] epoch=1, iter=40/6000, loss=1.1329, lr=0.001228, batch_cost=3.3041, reader_cost=0.00015, ips=1.2106 samples/sec | ETA 05:28:12\n",
      "2021-06-29 20:05:06 [INFO]\t[TRAIN] epoch=1, iter=50/6000, loss=1.1537, lr=0.001223, batch_cost=3.3079, reader_cost=0.00021, ips=1.2092 samples/sec | ETA 05:28:01\n",
      "2021-06-29 20:05:40 [INFO]\t[TRAIN] epoch=1, iter=60/6000, loss=1.0135, lr=0.001217, batch_cost=3.3121, reader_cost=0.00017, ips=1.2077 samples/sec | ETA 05:27:54\n",
      "2021-06-29 20:06:13 [INFO]\t[TRAIN] epoch=1, iter=70/6000, loss=0.9350, lr=0.001212, batch_cost=3.2959, reader_cost=0.00016, ips=1.2136 samples/sec | ETA 05:25:44\n",
      "2021-06-29 20:06:46 [INFO]\t[TRAIN] epoch=1, iter=80/6000, loss=0.9495, lr=0.001206, batch_cost=3.3029, reader_cost=0.00015, ips=1.2111 samples/sec | ETA 05:25:53\n",
      "2021-06-29 20:07:19 [INFO]\t[TRAIN] epoch=1, iter=90/6000, loss=0.9050, lr=0.001200, batch_cost=3.2972, reader_cost=0.00014, ips=1.2132 samples/sec | ETA 05:24:46\n",
      "2021-06-29 20:07:52 [INFO]\t[TRAIN] epoch=1, iter=100/6000, loss=0.9859, lr=0.001195, batch_cost=3.3057, reader_cost=0.00015, ips=1.2100 samples/sec | ETA 05:25:03\n",
      "2021-06-29 20:08:25 [INFO]\t[TRAIN] epoch=1, iter=110/6000, loss=0.8594, lr=0.001189, batch_cost=3.3057, reader_cost=0.00015, ips=1.2100 samples/sec | ETA 05:24:30\n",
      "2021-06-29 20:08:58 [INFO]\t[TRAIN] epoch=1, iter=120/6000, loss=0.7662, lr=0.001184, batch_cost=3.3078, reader_cost=0.00015, ips=1.2093 samples/sec | ETA 05:24:09\n",
      "2021-06-29 20:09:31 [INFO]\t[TRAIN] epoch=1, iter=130/6000, loss=0.6194, lr=0.001178, batch_cost=3.2950, reader_cost=0.00015, ips=1.2140 samples/sec | ETA 05:22:21\n",
      "2021-06-29 20:10:04 [INFO]\t[TRAIN] epoch=1, iter=140/6000, loss=0.6374, lr=0.001172, batch_cost=3.2871, reader_cost=0.00016, ips=1.2169 samples/sec | ETA 05:21:02\n",
      "2021-06-29 20:10:36 [INFO]\t[TRAIN] epoch=1, iter=150/6000, loss=0.7829, lr=0.001167, batch_cost=3.2939, reader_cost=0.00019, ips=1.2144 samples/sec | ETA 05:21:09\n",
      "2021-06-29 20:11:10 [INFO]\t[TRAIN] epoch=1, iter=160/6000, loss=0.6935, lr=0.001161, batch_cost=3.3025, reader_cost=0.00020, ips=1.2112 samples/sec | ETA 05:21:26\n",
      "2021-06-29 20:11:43 [INFO]\t[TRAIN] epoch=1, iter=170/6000, loss=0.7280, lr=0.001155, batch_cost=3.2989, reader_cost=0.00017, ips=1.2125 samples/sec | ETA 05:20:32\n",
      "2021-06-29 20:12:15 [INFO]\t[TRAIN] epoch=1, iter=180/6000, loss=0.7820, lr=0.001150, batch_cost=3.2613, reader_cost=0.00017, ips=1.2265 samples/sec | ETA 05:16:20\n",
      "2021-06-29 20:12:49 [INFO]\t[TRAIN] epoch=2, iter=190/6000, loss=0.7188, lr=0.001144, batch_cost=3.3529, reader_cost=0.06273, ips=1.1930 samples/sec | ETA 05:24:40\n",
      "2021-06-29 20:13:22 [INFO]\t[TRAIN] epoch=2, iter=200/6000, loss=0.6478, lr=0.001139, batch_cost=3.3084, reader_cost=0.00015, ips=1.2090 samples/sec | ETA 05:19:48\n",
      "2021-06-29 20:13:22 [INFO]\tStart evaluating (total_samples=80, total_iters=80)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/math_op_patch.py:238: UserWarning: The dtype of left and right variables are not the same, left dtype is VarType.INT32, but right dtype is VarType.BOOL, the right dtype will convert to VarType.INT32\n",
      "  format(lhs_dtype, rhs_dtype, lhs_dtype))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/math_op_patch.py:238: UserWarning: The dtype of left and right variables are not the same, left dtype is VarType.INT64, but right dtype is VarType.BOOL, the right dtype will convert to VarType.INT64\n",
      "  format(lhs_dtype, rhs_dtype, lhs_dtype))\n",
      "80/80 [==============================] - 23s 290ms/step - batch_cost: 0.2885 - reader cost: 0.06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-29 20:13:45 [INFO]\t[EVAL] #Images=80 mIoU=0.6323 Acc=0.9778 Kappa=0.4349 \n",
      "2021-06-29 20:13:45 [INFO]\t[EVAL] Class IoU: \n",
      "[0.287  0.9776]\n",
      "2021-06-29 20:13:45 [INFO]\t[EVAL] Class Acc: \n",
      "[0.3928 0.9914]\n",
      "2021-06-29 20:13:54 [INFO]\t[EVAL] The model with the best validation mIoU (0.6323) was saved at iter 200.\n",
      "2021-06-29 20:14:27 [INFO]\t[TRAIN] epoch=2, iter=210/6000, loss=0.7635, lr=0.001133, batch_cost=3.2989, reader_cost=0.00015, ips=1.2125 samples/sec | ETA 05:18:20\n",
      "2021-06-29 20:15:00 [INFO]\t[TRAIN] epoch=2, iter=220/6000, loss=0.5720, lr=0.001127, batch_cost=3.2914, reader_cost=0.00014, ips=1.2153 samples/sec | ETA 05:17:04\n",
      "2021-06-29 20:15:33 [INFO]\t[TRAIN] epoch=2, iter=230/6000, loss=0.5420, lr=0.001122, batch_cost=3.2829, reader_cost=0.00014, ips=1.2184 samples/sec | ETA 05:15:42\n",
      "2021-06-29 20:16:05 [INFO]\t[TRAIN] epoch=2, iter=240/6000, loss=0.6243, lr=0.001116, batch_cost=3.2769, reader_cost=0.00014, ips=1.2207 samples/sec | ETA 05:14:34\n",
      "2021-06-29 20:16:39 [INFO]\t[TRAIN] epoch=2, iter=250/6000, loss=0.7013, lr=0.001110, batch_cost=3.3017, reader_cost=0.00014, ips=1.2115 samples/sec | ETA 05:16:24\n",
      "2021-06-29 20:17:11 [INFO]\t[TRAIN] epoch=2, iter=260/6000, loss=0.6284, lr=0.001105, batch_cost=3.2891, reader_cost=0.00014, ips=1.2161 samples/sec | ETA 05:14:39\n",
      "2021-06-29 20:17:44 [INFO]\t[TRAIN] epoch=2, iter=270/6000, loss=0.6849, lr=0.001099, batch_cost=3.2953, reader_cost=0.00019, ips=1.2138 samples/sec | ETA 05:14:42\n",
      "2021-06-29 20:18:17 [INFO]\t[TRAIN] epoch=2, iter=280/6000, loss=0.6138, lr=0.001093, batch_cost=3.2992, reader_cost=0.00015, ips=1.2124 samples/sec | ETA 05:14:31\n",
      "2021-06-29 20:18:50 [INFO]\t[TRAIN] epoch=2, iter=290/6000, loss=0.5393, lr=0.001088, batch_cost=3.2848, reader_cost=0.00019, ips=1.2177 samples/sec | ETA 05:12:36\n",
      "2021-06-29 20:19:23 [INFO]\t[TRAIN] epoch=2, iter=300/6000, loss=0.6888, lr=0.001082, batch_cost=3.3012, reader_cost=0.00020, ips=1.2117 samples/sec | ETA 05:13:36\n",
      "2021-06-29 20:19:56 [INFO]\t[TRAIN] epoch=2, iter=310/6000, loss=0.5662, lr=0.001077, batch_cost=3.2827, reader_cost=0.00014, ips=1.2185 samples/sec | ETA 05:11:18\n",
      "2021-06-29 20:20:29 [INFO]\t[TRAIN] epoch=2, iter=320/6000, loss=0.5591, lr=0.001071, batch_cost=3.2854, reader_cost=0.00016, ips=1.2175 samples/sec | ETA 05:11:01\n",
      "2021-06-29 20:21:02 [INFO]\t[TRAIN] epoch=2, iter=330/6000, loss=0.4608, lr=0.001065, batch_cost=3.2837, reader_cost=0.00014, ips=1.2182 samples/sec | ETA 05:10:18\n",
      "2021-06-29 20:21:35 [INFO]\t[TRAIN] epoch=2, iter=340/6000, loss=0.5003, lr=0.001060, batch_cost=3.2862, reader_cost=0.00015, ips=1.2172 samples/sec | ETA 05:09:59\n",
      "2021-06-29 20:22:08 [INFO]\t[TRAIN] epoch=2, iter=350/6000, loss=0.5410, lr=0.001054, batch_cost=3.2895, reader_cost=0.00016, ips=1.2160 samples/sec | ETA 05:09:45\n",
      "2021-06-29 20:22:40 [INFO]\t[TRAIN] epoch=2, iter=360/6000, loss=0.5962, lr=0.001048, batch_cost=3.2468, reader_cost=0.00015, ips=1.2320 samples/sec | ETA 05:05:11\n",
      "2021-06-29 20:23:14 [INFO]\t[TRAIN] epoch=3, iter=370/6000, loss=0.5618, lr=0.001042, batch_cost=3.3805, reader_cost=0.07756, ips=1.1833 samples/sec | ETA 05:17:12\n",
      "2021-06-29 20:23:47 [INFO]\t[TRAIN] epoch=3, iter=380/6000, loss=0.5752, lr=0.001037, batch_cost=3.2892, reader_cost=0.00015, ips=1.2161 samples/sec | ETA 05:08:05\n",
      "2021-06-29 20:24:20 [INFO]\t[TRAIN] epoch=3, iter=390/6000, loss=0.6708, lr=0.001031, batch_cost=3.2909, reader_cost=0.00016, ips=1.2155 samples/sec | ETA 05:07:41\n",
      "2021-06-29 20:24:52 [INFO]\t[TRAIN] epoch=3, iter=400/6000, loss=0.4479, lr=0.001025, batch_cost=3.2910, reader_cost=0.00019, ips=1.2154 samples/sec | ETA 05:07:09\n",
      "2021-06-29 20:24:53 [INFO]\tStart evaluating (total_samples=80, total_iters=80)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 23s 287ms/step - batch_cost: 0.2853 - reader cost: 0.06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-29 20:25:15 [INFO]\t[EVAL] #Images=80 mIoU=0.6343 Acc=0.9873 Kappa=0.4345 \n",
      "2021-06-29 20:25:15 [INFO]\t[EVAL] Class IoU: \n",
      "[0.2813 0.9872]\n",
      "2021-06-29 20:25:15 [INFO]\t[EVAL] Class Acc: \n",
      "[0.9242 0.9876]\n",
      "2021-06-29 20:25:24 [INFO]\t[EVAL] The model with the best validation mIoU (0.6343) was saved at iter 400.\n",
      "2021-06-29 20:25:57 [INFO]\t[TRAIN] epoch=3, iter=410/6000, loss=0.5000, lr=0.001020, batch_cost=3.2840, reader_cost=0.00014, ips=1.2180 samples/sec | ETA 05:05:57\n",
      "2021-06-29 20:26:30 [INFO]\t[TRAIN] epoch=3, iter=420/6000, loss=0.6092, lr=0.001014, batch_cost=3.2982, reader_cost=0.00015, ips=1.2128 samples/sec | ETA 05:06:44\n",
      "2021-06-29 20:27:03 [INFO]\t[TRAIN] epoch=3, iter=430/6000, loss=0.4420, lr=0.001008, batch_cost=3.2777, reader_cost=0.00014, ips=1.2204 samples/sec | ETA 05:04:16\n",
      "2021-06-29 20:27:36 [INFO]\t[TRAIN] epoch=3, iter=440/6000, loss=0.4608, lr=0.001003, batch_cost=3.2860, reader_cost=0.00014, ips=1.2173 samples/sec | ETA 05:04:30\n",
      "2021-06-29 20:28:09 [INFO]\t[TRAIN] epoch=3, iter=450/6000, loss=0.5699, lr=0.000997, batch_cost=3.2860, reader_cost=0.00015, ips=1.2173 samples/sec | ETA 05:03:57\n",
      "2021-06-29 20:28:42 [INFO]\t[TRAIN] epoch=3, iter=460/6000, loss=0.5350, lr=0.000991, batch_cost=3.3103, reader_cost=0.00014, ips=1.2084 samples/sec | ETA 05:05:38\n",
      "2021-06-29 20:29:15 [INFO]\t[TRAIN] epoch=3, iter=470/6000, loss=0.4454, lr=0.000985, batch_cost=3.3145, reader_cost=0.00015, ips=1.2068 samples/sec | ETA 05:05:29\n",
      "2021-06-29 20:29:48 [INFO]\t[TRAIN] epoch=3, iter=480/6000, loss=0.4483, lr=0.000980, batch_cost=3.2825, reader_cost=0.00014, ips=1.2186 samples/sec | ETA 05:01:59\n",
      "2021-06-29 20:30:21 [INFO]\t[TRAIN] epoch=3, iter=490/6000, loss=0.4499, lr=0.000974, batch_cost=3.2942, reader_cost=0.00014, ips=1.2143 samples/sec | ETA 05:02:30\n",
      "2021-06-29 20:30:54 [INFO]\t[TRAIN] epoch=3, iter=500/6000, loss=0.4894, lr=0.000968, batch_cost=3.2995, reader_cost=0.00015, ips=1.2123 samples/sec | ETA 05:02:27\n",
      "2021-06-29 20:31:27 [INFO]\t[TRAIN] epoch=3, iter=510/6000, loss=0.4994, lr=0.000963, batch_cost=3.3068, reader_cost=0.00019, ips=1.2096 samples/sec | ETA 05:02:34\n",
      "2021-06-29 20:32:00 [INFO]\t[TRAIN] epoch=3, iter=520/6000, loss=0.3778, lr=0.000957, batch_cost=3.2832, reader_cost=0.00014, ips=1.2183 samples/sec | ETA 04:59:52\n",
      "2021-06-29 20:32:33 [INFO]\t[TRAIN] epoch=3, iter=530/6000, loss=0.3756, lr=0.000951, batch_cost=3.2933, reader_cost=0.00014, ips=1.2146 samples/sec | ETA 05:00:14\n",
      "2021-06-29 20:33:05 [INFO]\t[TRAIN] epoch=3, iter=540/6000, loss=0.4862, lr=0.000945, batch_cost=3.2388, reader_cost=0.00014, ips=1.2350 samples/sec | ETA 04:54:44\n",
      "2021-06-29 20:33:38 [INFO]\t[TRAIN] epoch=4, iter=550/6000, loss=0.3361, lr=0.000940, batch_cost=3.3415, reader_cost=0.06188, ips=1.1971 samples/sec | ETA 05:03:31\n",
      "2021-06-29 20:34:11 [INFO]\t[TRAIN] epoch=4, iter=560/6000, loss=0.4250, lr=0.000934, batch_cost=3.2974, reader_cost=0.00018, ips=1.2131 samples/sec | ETA 04:58:58\n",
      "2021-06-29 20:34:44 [INFO]\t[TRAIN] epoch=4, iter=570/6000, loss=0.3898, lr=0.000928, batch_cost=3.3138, reader_cost=0.00016, ips=1.2071 samples/sec | ETA 04:59:53\n",
      "2021-06-29 20:35:17 [INFO]\t[TRAIN] epoch=4, iter=580/6000, loss=0.3525, lr=0.000922, batch_cost=3.2918, reader_cost=0.00014, ips=1.2151 samples/sec | ETA 04:57:21\n",
      "2021-06-29 20:35:50 [INFO]\t[TRAIN] epoch=4, iter=590/6000, loss=0.3951, lr=0.000917, batch_cost=3.2865, reader_cost=0.00015, ips=1.2171 samples/sec | ETA 04:56:19\n",
      "2021-06-29 20:36:23 [INFO]\t[TRAIN] epoch=4, iter=600/6000, loss=0.3755, lr=0.000911, batch_cost=3.2713, reader_cost=0.00013, ips=1.2228 samples/sec | ETA 04:54:25\n",
      "2021-06-29 20:36:23 [INFO]\tStart evaluating (total_samples=80, total_iters=80)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 23s 290ms/step - batch_cost: 0.2884 - reader cost: 0.06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-29 20:36:46 [INFO]\t[EVAL] #Images=80 mIoU=0.7365 Acc=0.9896 Kappa=0.6466 \n",
      "2021-06-29 20:36:46 [INFO]\t[EVAL] Class IoU: \n",
      "[0.4834 0.9895]\n",
      "2021-06-29 20:36:46 [INFO]\t[EVAL] Class Acc: \n",
      "[0.775  0.9923]\n",
      "2021-06-29 20:36:54 [INFO]\t[EVAL] The model with the best validation mIoU (0.7365) was saved at iter 600.\n",
      "2021-06-29 20:37:27 [INFO]\t[TRAIN] epoch=4, iter=610/6000, loss=0.3875, lr=0.000905, batch_cost=3.2836, reader_cost=0.00014, ips=1.2182 samples/sec | ETA 04:54:58\n",
      "2021-06-29 20:38:00 [INFO]\t[TRAIN] epoch=4, iter=620/6000, loss=0.5381, lr=0.000899, batch_cost=3.2856, reader_cost=0.00014, ips=1.2174 samples/sec | ETA 04:54:36\n",
      "2021-06-29 20:38:33 [INFO]\t[TRAIN] epoch=4, iter=630/6000, loss=0.4103, lr=0.000893, batch_cost=3.2916, reader_cost=0.00016, ips=1.2152 samples/sec | ETA 04:54:35\n",
      "2021-06-29 20:39:06 [INFO]\t[TRAIN] epoch=4, iter=640/6000, loss=0.3785, lr=0.000888, batch_cost=3.2893, reader_cost=0.00014, ips=1.2161 samples/sec | ETA 04:53:50\n",
      "2021-06-29 20:39:39 [INFO]\t[TRAIN] epoch=4, iter=650/6000, loss=0.3228, lr=0.000882, batch_cost=3.2951, reader_cost=0.00014, ips=1.2139 samples/sec | ETA 04:53:48\n",
      "2021-06-29 20:40:12 [INFO]\t[TRAIN] epoch=4, iter=660/6000, loss=0.4500, lr=0.000876, batch_cost=3.3110, reader_cost=0.00014, ips=1.2081 samples/sec | ETA 04:54:40\n",
      "2021-06-29 20:40:45 [INFO]\t[TRAIN] epoch=4, iter=670/6000, loss=0.3720, lr=0.000870, batch_cost=3.2971, reader_cost=0.00017, ips=1.2132 samples/sec | ETA 04:52:53\n",
      "2021-06-29 20:41:18 [INFO]\t[TRAIN] epoch=4, iter=680/6000, loss=0.2935, lr=0.000864, batch_cost=3.2953, reader_cost=0.00014, ips=1.2138 samples/sec | ETA 04:52:11\n",
      "2021-06-29 20:41:51 [INFO]\t[TRAIN] epoch=4, iter=690/6000, loss=0.3574, lr=0.000859, batch_cost=3.2783, reader_cost=0.00015, ips=1.2201 samples/sec | ETA 04:50:07\n",
      "2021-06-29 20:42:24 [INFO]\t[TRAIN] epoch=4, iter=700/6000, loss=0.2764, lr=0.000853, batch_cost=3.2844, reader_cost=0.00019, ips=1.2179 samples/sec | ETA 04:50:07\n",
      "2021-06-29 20:42:57 [INFO]\t[TRAIN] epoch=4, iter=710/6000, loss=0.3555, lr=0.000847, batch_cost=3.2933, reader_cost=0.00014, ips=1.2146 samples/sec | ETA 04:50:21\n",
      "2021-06-29 20:43:29 [INFO]\t[TRAIN] epoch=4, iter=720/6000, loss=0.4288, lr=0.000841, batch_cost=3.2494, reader_cost=0.00015, ips=1.2310 samples/sec | ETA 04:45:56\n",
      "2021-06-29 20:44:03 [INFO]\t[TRAIN] epoch=5, iter=730/6000, loss=0.3454, lr=0.000835, batch_cost=3.3780, reader_cost=0.07732, ips=1.1841 samples/sec | ETA 04:56:41\n",
      "2021-06-29 20:44:36 [INFO]\t[TRAIN] epoch=5, iter=740/6000, loss=0.3082, lr=0.000830, batch_cost=3.2978, reader_cost=0.00015, ips=1.2129 samples/sec | ETA 04:49:06\n",
      "2021-06-29 20:45:09 [INFO]\t[TRAIN] epoch=5, iter=750/6000, loss=0.3163, lr=0.000824, batch_cost=3.2862, reader_cost=0.00014, ips=1.2172 samples/sec | ETA 04:47:32\n",
      "2021-06-29 20:45:42 [INFO]\t[TRAIN] epoch=5, iter=760/6000, loss=0.2775, lr=0.000818, batch_cost=3.3165, reader_cost=0.00018, ips=1.2061 samples/sec | ETA 04:49:38\n",
      "2021-06-29 20:46:15 [INFO]\t[TRAIN] epoch=5, iter=770/6000, loss=0.3646, lr=0.000812, batch_cost=3.2784, reader_cost=0.00016, ips=1.2201 samples/sec | ETA 04:45:46\n",
      "2021-06-29 20:46:47 [INFO]\t[TRAIN] epoch=5, iter=780/6000, loss=0.3146, lr=0.000806, batch_cost=3.2813, reader_cost=0.00016, ips=1.2190 samples/sec | ETA 04:45:28\n",
      "2021-06-29 20:47:20 [INFO]\t[TRAIN] epoch=5, iter=790/6000, loss=0.2756, lr=0.000800, batch_cost=3.2923, reader_cost=0.00014, ips=1.2150 samples/sec | ETA 04:45:52\n",
      "2021-06-29 20:47:53 [INFO]\t[TRAIN] epoch=5, iter=800/6000, loss=0.2417, lr=0.000795, batch_cost=3.2788, reader_cost=0.00014, ips=1.2200 samples/sec | ETA 04:44:09\n",
      "2021-06-29 20:47:53 [INFO]\tStart evaluating (total_samples=80, total_iters=80)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 23s 288ms/step - batch_cost: 0.2865 - reader cost: 0.06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-29 20:48:16 [INFO]\t[EVAL] #Images=80 mIoU=0.7483 Acc=0.9871 Kappa=0.6687 \n",
      "2021-06-29 20:48:16 [INFO]\t[EVAL] Class IoU: \n",
      "[0.5097 0.9869]\n",
      "2021-06-29 20:48:16 [INFO]\t[EVAL] Class Acc: \n",
      "[0.5983 0.996 ]\n",
      "2021-06-29 20:48:23 [INFO]\t[EVAL] The model with the best validation mIoU (0.7483) was saved at iter 800.\n",
      "2021-06-29 20:48:56 [INFO]\t[TRAIN] epoch=5, iter=810/6000, loss=0.3677, lr=0.000789, batch_cost=3.2958, reader_cost=0.00017, ips=1.2137 samples/sec | ETA 04:45:05\n",
      "2021-06-29 20:49:29 [INFO]\t[TRAIN] epoch=5, iter=820/6000, loss=0.3508, lr=0.000783, batch_cost=3.2879, reader_cost=0.00014, ips=1.2166 samples/sec | ETA 04:43:51\n",
      "2021-06-29 20:50:01 [INFO]\t[TRAIN] epoch=5, iter=830/6000, loss=0.2385, lr=0.000777, batch_cost=3.2893, reader_cost=0.00015, ips=1.2161 samples/sec | ETA 04:43:25\n",
      "2021-06-29 20:50:34 [INFO]\t[TRAIN] epoch=5, iter=840/6000, loss=0.3752, lr=0.000771, batch_cost=3.2780, reader_cost=0.00015, ips=1.2203 samples/sec | ETA 04:41:54\n",
      "2021-06-29 20:51:07 [INFO]\t[TRAIN] epoch=5, iter=850/6000, loss=0.3518, lr=0.000765, batch_cost=3.2932, reader_cost=0.00017, ips=1.2146 samples/sec | ETA 04:42:40\n",
      "2021-06-29 20:51:40 [INFO]\t[TRAIN] epoch=5, iter=860/6000, loss=0.4319, lr=0.000759, batch_cost=3.2718, reader_cost=0.00017, ips=1.2226 samples/sec | ETA 04:40:16\n",
      "2021-06-29 20:52:13 [INFO]\t[TRAIN] epoch=5, iter=870/6000, loss=0.2836, lr=0.000753, batch_cost=3.2855, reader_cost=0.00015, ips=1.2175 samples/sec | ETA 04:40:54\n",
      "2021-06-29 20:52:46 [INFO]\t[TRAIN] epoch=5, iter=880/6000, loss=0.3941, lr=0.000747, batch_cost=3.2944, reader_cost=0.00014, ips=1.2142 samples/sec | ETA 04:41:07\n",
      "2021-06-29 20:53:19 [INFO]\t[TRAIN] epoch=5, iter=890/6000, loss=0.4440, lr=0.000742, batch_cost=3.2968, reader_cost=0.00015, ips=1.2133 samples/sec | ETA 04:40:46\n",
      "2021-06-29 20:53:51 [INFO]\t[TRAIN] epoch=5, iter=900/6000, loss=0.2672, lr=0.000736, batch_cost=3.2489, reader_cost=0.00015, ips=1.2312 samples/sec | ETA 04:36:09\n",
      "2021-06-29 20:54:25 [INFO]\t[TRAIN] epoch=6, iter=910/6000, loss=0.2638, lr=0.000730, batch_cost=3.3411, reader_cost=0.05984, ips=1.1972 samples/sec | ETA 04:43:26\n",
      "2021-06-29 20:54:57 [INFO]\t[TRAIN] epoch=6, iter=920/6000, loss=0.3372, lr=0.000724, batch_cost=3.2847, reader_cost=0.00014, ips=1.2178 samples/sec | ETA 04:38:06\n",
      "2021-06-29 20:55:30 [INFO]\t[TRAIN] epoch=6, iter=930/6000, loss=0.2992, lr=0.000718, batch_cost=3.2984, reader_cost=0.00014, ips=1.2127 samples/sec | ETA 04:38:42\n",
      "2021-06-29 20:56:03 [INFO]\t[TRAIN] epoch=6, iter=940/6000, loss=0.3057, lr=0.000712, batch_cost=3.2865, reader_cost=0.00018, ips=1.2171 samples/sec | ETA 04:37:09\n",
      "2021-06-29 20:56:36 [INFO]\t[TRAIN] epoch=6, iter=950/6000, loss=0.3129, lr=0.000706, batch_cost=3.2913, reader_cost=0.00017, ips=1.2153 samples/sec | ETA 04:37:01\n",
      "2021-06-29 20:57:09 [INFO]\t[TRAIN] epoch=6, iter=960/6000, loss=0.3169, lr=0.000700, batch_cost=3.3232, reader_cost=0.00014, ips=1.2037 samples/sec | ETA 04:39:08\n",
      "2021-06-29 20:57:43 [INFO]\t[TRAIN] epoch=6, iter=970/6000, loss=0.2434, lr=0.000694, batch_cost=3.3168, reader_cost=0.00020, ips=1.2060 samples/sec | ETA 04:38:03\n",
      "2021-06-29 20:58:16 [INFO]\t[TRAIN] epoch=6, iter=980/6000, loss=0.3050, lr=0.000688, batch_cost=3.3004, reader_cost=0.00015, ips=1.2120 samples/sec | ETA 04:36:08\n",
      "2021-06-29 20:58:48 [INFO]\t[TRAIN] epoch=6, iter=990/6000, loss=0.2159, lr=0.000682, batch_cost=3.2807, reader_cost=0.00014, ips=1.2193 samples/sec | ETA 04:33:56\n",
      "2021-06-29 20:59:22 [INFO]\t[TRAIN] epoch=6, iter=1000/6000, loss=0.1829, lr=0.000676, batch_cost=3.3087, reader_cost=0.00016, ips=1.2089 samples/sec | ETA 04:35:43\n",
      "2021-06-29 20:59:22 [INFO]\tStart evaluating (total_samples=80, total_iters=80)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 24s 294ms/step - batch_cost: 0.2931 - reader cost: 0.066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-29 20:59:45 [INFO]\t[EVAL] #Images=80 mIoU=0.7555 Acc=0.9868 Kappa=0.6815 \n",
      "2021-06-29 20:59:45 [INFO]\t[EVAL] Class IoU: \n",
      "[0.5244 0.9866]\n",
      "2021-06-29 20:59:45 [INFO]\t[EVAL] Class Acc: \n",
      "[0.5813 0.9972]\n",
      "2021-06-29 20:59:52 [INFO]\t[EVAL] The model with the best validation mIoU (0.7555) was saved at iter 1000.\n",
      "2021-06-29 21:00:24 [INFO]\t[TRAIN] epoch=6, iter=1010/6000, loss=0.3923, lr=0.000670, batch_cost=3.2814, reader_cost=0.00015, ips=1.2190 samples/sec | ETA 04:32:54\n",
      "2021-06-29 21:00:57 [INFO]\t[TRAIN] epoch=6, iter=1020/6000, loss=0.2468, lr=0.000664, batch_cost=3.3053, reader_cost=0.00018, ips=1.2102 samples/sec | ETA 04:34:20\n",
      "2021-06-29 21:01:30 [INFO]\t[TRAIN] epoch=6, iter=1030/6000, loss=0.2814, lr=0.000658, batch_cost=3.2953, reader_cost=0.00015, ips=1.2138 samples/sec | ETA 04:32:57\n",
      "2021-06-29 21:02:03 [INFO]\t[TRAIN] epoch=6, iter=1040/6000, loss=0.2591, lr=0.000652, batch_cost=3.2983, reader_cost=0.00018, ips=1.2127 samples/sec | ETA 04:32:39\n",
      "2021-06-29 21:02:37 [INFO]\t[TRAIN] epoch=6, iter=1050/6000, loss=0.2249, lr=0.000646, batch_cost=3.3264, reader_cost=0.00017, ips=1.2025 samples/sec | ETA 04:34:25\n",
      "2021-06-29 21:03:10 [INFO]\t[TRAIN] epoch=6, iter=1060/6000, loss=0.3144, lr=0.000640, batch_cost=3.2992, reader_cost=0.00015, ips=1.2124 samples/sec | ETA 04:31:37\n",
      "2021-06-29 21:03:42 [INFO]\t[TRAIN] epoch=6, iter=1070/6000, loss=0.3242, lr=0.000634, batch_cost=3.2858, reader_cost=0.00017, ips=1.2174 samples/sec | ETA 04:29:58\n",
      "2021-06-29 21:04:15 [INFO]\t[TRAIN] epoch=6, iter=1080/6000, loss=0.2533, lr=0.000628, batch_cost=3.2420, reader_cost=0.00015, ips=1.2338 samples/sec | ETA 04:25:50\n",
      "2021-06-29 21:04:49 [INFO]\t[TRAIN] epoch=7, iter=1090/6000, loss=0.2843, lr=0.000622, batch_cost=3.3750, reader_cost=0.07027, ips=1.1852 samples/sec | ETA 04:36:11\n",
      "2021-06-29 21:05:22 [INFO]\t[TRAIN] epoch=7, iter=1100/6000, loss=0.2213, lr=0.000616, batch_cost=3.2879, reader_cost=0.00015, ips=1.2166 samples/sec | ETA 04:28:30\n",
      "2021-06-29 21:05:55 [INFO]\t[TRAIN] epoch=7, iter=1110/6000, loss=0.2586, lr=0.000610, batch_cost=3.3014, reader_cost=0.00014, ips=1.2116 samples/sec | ETA 04:29:03\n",
      "2021-06-29 21:06:28 [INFO]\t[TRAIN] epoch=7, iter=1120/6000, loss=0.2304, lr=0.000604, batch_cost=3.2976, reader_cost=0.00014, ips=1.2130 samples/sec | ETA 04:28:12\n",
      "2021-06-29 21:07:01 [INFO]\t[TRAIN] epoch=7, iter=1130/6000, loss=0.2885, lr=0.000598, batch_cost=3.2986, reader_cost=0.00014, ips=1.2126 samples/sec | ETA 04:27:44\n",
      "2021-06-29 21:07:33 [INFO]\t[TRAIN] epoch=7, iter=1140/6000, loss=0.1973, lr=0.000592, batch_cost=3.2822, reader_cost=0.00014, ips=1.2187 samples/sec | ETA 04:25:51\n",
      "2021-06-29 21:08:06 [INFO]\t[TRAIN] epoch=7, iter=1150/6000, loss=0.3501, lr=0.000586, batch_cost=3.3118, reader_cost=0.00016, ips=1.2078 samples/sec | ETA 04:27:42\n",
      "2021-06-29 21:08:39 [INFO]\t[TRAIN] epoch=7, iter=1160/6000, loss=0.3227, lr=0.000580, batch_cost=3.2943, reader_cost=0.00015, ips=1.2142 samples/sec | ETA 04:25:44\n",
      "2021-06-29 21:09:12 [INFO]\t[TRAIN] epoch=7, iter=1170/6000, loss=0.2342, lr=0.000574, batch_cost=3.2825, reader_cost=0.00018, ips=1.2186 samples/sec | ETA 04:24:14\n",
      "2021-06-29 21:09:45 [INFO]\t[TRAIN] epoch=7, iter=1180/6000, loss=0.3028, lr=0.000568, batch_cost=3.3138, reader_cost=0.00015, ips=1.2071 samples/sec | ETA 04:26:12\n",
      "2021-06-29 21:10:19 [INFO]\t[TRAIN] epoch=7, iter=1190/6000, loss=0.2571, lr=0.000562, batch_cost=3.3139, reader_cost=0.00015, ips=1.2071 samples/sec | ETA 04:25:39\n",
      "2021-06-29 21:10:51 [INFO]\t[TRAIN] epoch=7, iter=1200/6000, loss=0.2505, lr=0.000556, batch_cost=3.2920, reader_cost=0.00014, ips=1.2151 samples/sec | ETA 04:23:21\n",
      "2021-06-29 21:10:51 [INFO]\tStart evaluating (total_samples=80, total_iters=80)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 23s 290ms/step - batch_cost: 0.2890 - reader cost: 0.06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-29 21:11:15 [INFO]\t[EVAL] #Images=80 mIoU=0.7798 Acc=0.9894 Kappa=0.7211 \n",
      "2021-06-29 21:11:15 [INFO]\t[EVAL] Class IoU: \n",
      "[0.5704 0.9892]\n",
      "2021-06-29 21:11:15 [INFO]\t[EVAL] Class Acc: \n",
      "[0.6558 0.9967]\n",
      "2021-06-29 21:11:21 [INFO]\t[EVAL] The model with the best validation mIoU (0.7798) was saved at iter 1200.\n",
      "2021-06-29 21:11:54 [INFO]\t[TRAIN] epoch=7, iter=1210/6000, loss=0.1855, lr=0.000550, batch_cost=3.3028, reader_cost=0.00016, ips=1.2111 samples/sec | ETA 04:23:40\n",
      "2021-06-29 21:12:27 [INFO]\t[TRAIN] epoch=7, iter=1220/6000, loss=0.2097, lr=0.000543, batch_cost=3.2912, reader_cost=0.00017, ips=1.2154 samples/sec | ETA 04:22:11\n",
      "2021-06-29 21:13:00 [INFO]\t[TRAIN] epoch=7, iter=1230/6000, loss=0.1913, lr=0.000537, batch_cost=3.2956, reader_cost=0.00013, ips=1.2137 samples/sec | ETA 04:22:00\n",
      "2021-06-29 21:13:33 [INFO]\t[TRAIN] epoch=7, iter=1240/6000, loss=0.2809, lr=0.000531, batch_cost=3.3050, reader_cost=0.00015, ips=1.2103 samples/sec | ETA 04:22:11\n",
      "2021-06-29 21:14:06 [INFO]\t[TRAIN] epoch=7, iter=1250/6000, loss=0.2109, lr=0.000525, batch_cost=3.2847, reader_cost=0.00015, ips=1.2178 samples/sec | ETA 04:20:02\n",
      "2021-06-29 21:14:39 [INFO]\t[TRAIN] epoch=7, iter=1260/6000, loss=0.2488, lr=0.000519, batch_cost=3.2570, reader_cost=0.00014, ips=1.2281 samples/sec | ETA 04:17:18\n",
      "2021-06-29 21:15:13 [INFO]\t[TRAIN] epoch=8, iter=1270/6000, loss=0.1908, lr=0.000513, batch_cost=3.3969, reader_cost=0.08896, ips=1.1775 samples/sec | ETA 04:27:47\n",
      "2021-06-29 21:15:45 [INFO]\t[TRAIN] epoch=8, iter=1280/6000, loss=0.2357, lr=0.000507, batch_cost=3.2786, reader_cost=0.00014, ips=1.2200 samples/sec | ETA 04:17:55\n",
      "2021-06-29 21:16:18 [INFO]\t[TRAIN] epoch=8, iter=1290/6000, loss=0.3379, lr=0.000500, batch_cost=3.2938, reader_cost=0.00015, ips=1.2144 samples/sec | ETA 04:18:33\n",
      "2021-06-29 21:16:51 [INFO]\t[TRAIN] epoch=8, iter=1300/6000, loss=0.2069, lr=0.000494, batch_cost=3.2959, reader_cost=0.00016, ips=1.2136 samples/sec | ETA 04:18:10\n",
      "2021-06-29 21:17:24 [INFO]\t[TRAIN] epoch=8, iter=1310/6000, loss=0.2292, lr=0.000488, batch_cost=3.2908, reader_cost=0.00014, ips=1.2155 samples/sec | ETA 04:17:13\n",
      "2021-06-29 21:17:57 [INFO]\t[TRAIN] epoch=8, iter=1320/6000, loss=0.2327, lr=0.000482, batch_cost=3.3011, reader_cost=0.00017, ips=1.2117 samples/sec | ETA 04:17:29\n",
      "2021-06-29 21:18:30 [INFO]\t[TRAIN] epoch=8, iter=1330/6000, loss=0.2200, lr=0.000476, batch_cost=3.3080, reader_cost=0.00014, ips=1.2092 samples/sec | ETA 04:17:28\n",
      "2021-06-29 21:19:03 [INFO]\t[TRAIN] epoch=8, iter=1340/6000, loss=0.3046, lr=0.000469, batch_cost=3.2756, reader_cost=0.00018, ips=1.2212 samples/sec | ETA 04:14:24\n",
      "2021-06-29 21:19:36 [INFO]\t[TRAIN] epoch=8, iter=1350/6000, loss=0.2255, lr=0.000463, batch_cost=3.2908, reader_cost=0.00014, ips=1.2155 samples/sec | ETA 04:15:02\n",
      "2021-06-29 21:20:09 [INFO]\t[TRAIN] epoch=8, iter=1360/6000, loss=0.3074, lr=0.000457, batch_cost=3.3048, reader_cost=0.00015, ips=1.2103 samples/sec | ETA 04:15:34\n",
      "2021-06-29 21:20:42 [INFO]\t[TRAIN] epoch=8, iter=1370/6000, loss=0.1805, lr=0.000451, batch_cost=3.2810, reader_cost=0.00014, ips=1.2192 samples/sec | ETA 04:13:10\n",
      "2021-06-29 21:21:15 [INFO]\t[TRAIN] epoch=8, iter=1380/6000, loss=0.1658, lr=0.000444, batch_cost=3.3045, reader_cost=0.00015, ips=1.2105 samples/sec | ETA 04:14:26\n",
      "2021-06-29 21:21:48 [INFO]\t[TRAIN] epoch=8, iter=1390/6000, loss=0.2773, lr=0.000438, batch_cost=3.2787, reader_cost=0.00015, ips=1.2200 samples/sec | ETA 04:11:55\n",
      "2021-06-29 21:22:20 [INFO]\t[TRAIN] epoch=8, iter=1400/6000, loss=0.1437, lr=0.000432, batch_cost=3.2722, reader_cost=0.00014, ips=1.2224 samples/sec | ETA 04:10:52\n",
      "2021-06-29 21:22:20 [INFO]\tStart evaluating (total_samples=80, total_iters=80)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 23s 292ms/step - batch_cost: 0.2908 - reader cost: 0.06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-29 21:22:44 [INFO]\t[EVAL] #Images=80 mIoU=0.7835 Acc=0.9887 Kappa=0.7274 \n",
      "2021-06-29 21:22:44 [INFO]\t[EVAL] Class IoU: \n",
      "[0.5785 0.9886]\n",
      "2021-06-29 21:22:44 [INFO]\t[EVAL] Class Acc: \n",
      "[0.6222 0.9981]\n",
      "2021-06-29 21:22:50 [INFO]\t[EVAL] The model with the best validation mIoU (0.7835) was saved at iter 1400.\n",
      "2021-06-29 21:23:23 [INFO]\t[TRAIN] epoch=8, iter=1410/6000, loss=0.1647, lr=0.000426, batch_cost=3.3064, reader_cost=0.00015, ips=1.2098 samples/sec | ETA 04:12:56\n",
      "2021-06-29 21:23:56 [INFO]\t[TRAIN] epoch=8, iter=1420/6000, loss=0.2653, lr=0.000419, batch_cost=3.2873, reader_cost=0.00014, ips=1.2168 samples/sec | ETA 04:10:55\n",
      "2021-06-29 21:24:29 [INFO]\t[TRAIN] epoch=8, iter=1430/6000, loss=0.1511, lr=0.000413, batch_cost=3.2999, reader_cost=0.00015, ips=1.2122 samples/sec | ETA 04:11:20\n",
      "2021-06-29 21:25:02 [INFO]\t[TRAIN] epoch=8, iter=1440/6000, loss=0.2301, lr=0.000407, batch_cost=3.2639, reader_cost=0.00014, ips=1.2255 samples/sec | ETA 04:08:03\n",
      "2021-06-29 21:25:35 [INFO]\t[TRAIN] epoch=9, iter=1450/6000, loss=0.1519, lr=0.000400, batch_cost=3.3572, reader_cost=0.07820, ips=1.1915 samples/sec | ETA 04:14:35\n",
      "2021-06-29 21:26:08 [INFO]\t[TRAIN] epoch=9, iter=1460/6000, loss=0.2397, lr=0.000394, batch_cost=3.2788, reader_cost=0.00017, ips=1.2199 samples/sec | ETA 04:08:05\n",
      "2021-06-29 21:26:41 [INFO]\t[TRAIN] epoch=9, iter=1470/6000, loss=0.2186, lr=0.000388, batch_cost=3.2943, reader_cost=0.00018, ips=1.2142 samples/sec | ETA 04:08:43\n",
      "2021-06-29 21:27:14 [INFO]\t[TRAIN] epoch=9, iter=1480/6000, loss=0.2277, lr=0.000381, batch_cost=3.3058, reader_cost=0.00014, ips=1.2100 samples/sec | ETA 04:09:02\n",
      "2021-06-29 21:27:47 [INFO]\t[TRAIN] epoch=9, iter=1490/6000, loss=0.2449, lr=0.000375, batch_cost=3.2863, reader_cost=0.00015, ips=1.2172 samples/sec | ETA 04:07:01\n",
      "2021-06-29 21:28:20 [INFO]\t[TRAIN] epoch=9, iter=1500/6000, loss=0.2309, lr=0.000369, batch_cost=3.3186, reader_cost=0.00015, ips=1.2053 samples/sec | ETA 04:08:53\n",
      "2021-06-29 21:28:53 [INFO]\t[TRAIN] epoch=9, iter=1510/6000, loss=0.2124, lr=0.000362, batch_cost=3.2829, reader_cost=0.00014, ips=1.2184 samples/sec | ETA 04:05:40\n",
      "2021-06-29 21:29:26 [INFO]\t[TRAIN] epoch=9, iter=1520/6000, loss=0.1796, lr=0.000356, batch_cost=3.3012, reader_cost=0.00018, ips=1.2117 samples/sec | ETA 04:06:29\n",
      "2021-06-29 21:29:59 [INFO]\t[TRAIN] epoch=9, iter=1530/6000, loss=0.1773, lr=0.000349, batch_cost=3.3008, reader_cost=0.00019, ips=1.2118 samples/sec | ETA 04:05:54\n",
      "2021-06-29 21:30:32 [INFO]\t[TRAIN] epoch=9, iter=1540/6000, loss=0.2668, lr=0.000343, batch_cost=3.3094, reader_cost=0.00018, ips=1.2087 samples/sec | ETA 04:05:59\n",
      "2021-06-29 21:31:05 [INFO]\t[TRAIN] epoch=9, iter=1550/6000, loss=0.1728, lr=0.000336, batch_cost=3.3110, reader_cost=0.00014, ips=1.2081 samples/sec | ETA 04:05:33\n",
      "2021-06-29 21:31:39 [INFO]\t[TRAIN] epoch=9, iter=1560/6000, loss=0.2036, lr=0.000330, batch_cost=3.3214, reader_cost=0.00015, ips=1.2043 samples/sec | ETA 04:05:46\n",
      "2021-06-29 21:32:12 [INFO]\t[TRAIN] epoch=9, iter=1570/6000, loss=0.2071, lr=0.000323, batch_cost=3.3125, reader_cost=0.00015, ips=1.2075 samples/sec | ETA 04:04:34\n",
      "2021-06-29 21:32:45 [INFO]\t[TRAIN] epoch=9, iter=1580/6000, loss=0.2288, lr=0.000317, batch_cost=3.3208, reader_cost=0.00015, ips=1.2045 samples/sec | ETA 04:04:37\n",
      "2021-06-29 21:33:18 [INFO]\t[TRAIN] epoch=9, iter=1590/6000, loss=0.1782, lr=0.000310, batch_cost=3.3126, reader_cost=0.00021, ips=1.2075 samples/sec | ETA 04:03:28\n",
      "2021-06-29 21:33:51 [INFO]\t[TRAIN] epoch=9, iter=1600/6000, loss=0.2152, lr=0.000304, batch_cost=3.3035, reader_cost=0.00016, ips=1.2109 samples/sec | ETA 04:02:15\n",
      "2021-06-29 21:33:51 [INFO]\tStart evaluating (total_samples=80, total_iters=80)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 23s 293ms/step - batch_cost: 0.2913 - reader cost: 0.066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-29 21:34:15 [INFO]\t[EVAL] #Images=80 mIoU=0.7790 Acc=0.9890 Kappa=0.7199 \n",
      "2021-06-29 21:34:15 [INFO]\t[EVAL] Class IoU: \n",
      "[0.5691 0.9889]\n",
      "2021-06-29 21:34:15 [INFO]\t[EVAL] Class Acc: \n",
      "[0.64   0.9971]\n",
      "2021-06-29 21:34:18 [INFO]\t[EVAL] The model with the best validation mIoU (0.7835) was saved at iter 1400.\n",
      "2021-06-29 21:34:51 [INFO]\t[TRAIN] epoch=9, iter=1610/6000, loss=0.2055, lr=0.000297, batch_cost=3.2905, reader_cost=0.00014, ips=1.2156 samples/sec | ETA 04:00:45\n",
      "2021-06-29 21:35:24 [INFO]\t[TRAIN] epoch=9, iter=1620/6000, loss=0.2084, lr=0.000291, batch_cost=3.2614, reader_cost=0.00014, ips=1.2265 samples/sec | ETA 03:58:04\n",
      "2021-06-29 21:35:58 [INFO]\t[TRAIN] epoch=10, iter=1630/6000, loss=0.1316, lr=0.000284, batch_cost=3.3759, reader_cost=0.07910, ips=1.1849 samples/sec | ETA 04:05:52\n",
      "2021-06-29 21:36:31 [INFO]\t[TRAIN] epoch=10, iter=1640/6000, loss=0.2221, lr=0.000278, batch_cost=3.2937, reader_cost=0.00014, ips=1.2144 samples/sec | ETA 03:59:20\n",
      "2021-06-29 21:37:04 [INFO]\t[TRAIN] epoch=10, iter=1650/6000, loss=0.2041, lr=0.000271, batch_cost=3.2947, reader_cost=0.00014, ips=1.2141 samples/sec | ETA 03:58:51\n",
      "2021-06-29 21:37:36 [INFO]\t[TRAIN] epoch=10, iter=1660/6000, loss=0.2081, lr=0.000264, batch_cost=3.2768, reader_cost=0.00014, ips=1.2207 samples/sec | ETA 03:57:01\n",
      "2021-06-29 21:38:09 [INFO]\t[TRAIN] epoch=10, iter=1670/6000, loss=0.1536, lr=0.000258, batch_cost=3.2901, reader_cost=0.00013, ips=1.2158 samples/sec | ETA 03:57:26\n",
      "2021-06-29 21:38:42 [INFO]\t[TRAIN] epoch=10, iter=1680/6000, loss=0.2515, lr=0.000251, batch_cost=3.2947, reader_cost=0.00015, ips=1.2141 samples/sec | ETA 03:57:13\n",
      "2021-06-29 21:39:15 [INFO]\t[TRAIN] epoch=10, iter=1690/6000, loss=0.1723, lr=0.000244, batch_cost=3.2964, reader_cost=0.00014, ips=1.2134 samples/sec | ETA 03:56:47\n",
      "2021-06-29 21:39:48 [INFO]\t[TRAIN] epoch=10, iter=1700/6000, loss=0.1825, lr=0.000238, batch_cost=3.2896, reader_cost=0.00014, ips=1.2160 samples/sec | ETA 03:55:45\n",
      "2021-06-29 21:40:21 [INFO]\t[TRAIN] epoch=10, iter=1710/6000, loss=0.2263, lr=0.000231, batch_cost=3.3027, reader_cost=0.00016, ips=1.2111 samples/sec | ETA 03:56:08\n",
      "2021-06-29 21:40:54 [INFO]\t[TRAIN] epoch=10, iter=1720/6000, loss=0.1719, lr=0.000224, batch_cost=3.3053, reader_cost=0.00015, ips=1.2102 samples/sec | ETA 03:55:46\n",
      "2021-06-29 21:41:27 [INFO]\t[TRAIN] epoch=10, iter=1730/6000, loss=0.1956, lr=0.000217, batch_cost=3.2942, reader_cost=0.00014, ips=1.2143 samples/sec | ETA 03:54:26\n",
      "2021-06-29 21:42:00 [INFO]\t[TRAIN] epoch=10, iter=1740/6000, loss=0.1428, lr=0.000210, batch_cost=3.2824, reader_cost=0.00014, ips=1.2186 samples/sec | ETA 03:53:03\n",
      "2021-06-29 21:42:33 [INFO]\t[TRAIN] epoch=10, iter=1750/6000, loss=0.1885, lr=0.000204, batch_cost=3.2966, reader_cost=0.00014, ips=1.2134 samples/sec | ETA 03:53:30\n",
      "2021-06-29 21:43:06 [INFO]\t[TRAIN] epoch=10, iter=1760/6000, loss=0.1958, lr=0.000197, batch_cost=3.3033, reader_cost=0.00016, ips=1.2109 samples/sec | ETA 03:53:25\n",
      "2021-06-29 21:43:39 [INFO]\t[TRAIN] epoch=10, iter=1770/6000, loss=0.1722, lr=0.000190, batch_cost=3.2825, reader_cost=0.00017, ips=1.2186 samples/sec | ETA 03:51:24\n",
      "2021-06-29 21:44:12 [INFO]\t[TRAIN] epoch=10, iter=1780/6000, loss=0.2146, lr=0.000183, batch_cost=3.2840, reader_cost=0.00015, ips=1.2180 samples/sec | ETA 03:50:58\n",
      "2021-06-29 21:44:44 [INFO]\t[TRAIN] epoch=10, iter=1790/6000, loss=0.2030, lr=0.000176, batch_cost=3.2767, reader_cost=0.00015, ips=1.2207 samples/sec | ETA 03:49:54\n",
      "2021-06-29 21:45:17 [INFO]\t[TRAIN] epoch=10, iter=1800/6000, loss=0.1767, lr=0.000169, batch_cost=3.2530, reader_cost=0.00021, ips=1.2296 samples/sec | ETA 03:47:42\n",
      "2021-06-29 21:45:17 [INFO]\tStart evaluating (total_samples=80, total_iters=80)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 24s 300ms/step - batch_cost: 0.2986 - reader cost: 0.074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-29 21:45:41 [INFO]\t[EVAL] #Images=80 mIoU=0.7578 Acc=0.9863 Kappa=0.6858 \n",
      "2021-06-29 21:45:41 [INFO]\t[EVAL] Class IoU: \n",
      "[0.5296 0.9861]\n",
      "2021-06-29 21:45:41 [INFO]\t[EVAL] Class Acc: \n",
      "[0.5666 0.998 ]\n",
      "2021-06-29 21:45:45 [INFO]\t[EVAL] The model with the best validation mIoU (0.7835) was saved at iter 1400.\n",
      "2021-06-29 21:46:18 [INFO]\t[TRAIN] epoch=11, iter=1810/6000, loss=0.2022, lr=0.000162, batch_cost=3.3778, reader_cost=0.07823, ips=1.1842 samples/sec | ETA 03:55:52\n",
      "2021-06-29 21:46:51 [INFO]\t[TRAIN] epoch=11, iter=1820/6000, loss=0.2157, lr=0.000155, batch_cost=3.2938, reader_cost=0.00014, ips=1.2144 samples/sec | ETA 03:49:28\n",
      "2021-06-29 21:47:24 [INFO]\t[TRAIN] epoch=11, iter=1830/6000, loss=0.1702, lr=0.000148, batch_cost=3.2909, reader_cost=0.00018, ips=1.2155 samples/sec | ETA 03:48:43\n",
      "2021-06-29 21:47:57 [INFO]\t[TRAIN] epoch=11, iter=1840/6000, loss=0.2137, lr=0.000141, batch_cost=3.2868, reader_cost=0.00014, ips=1.2170 samples/sec | ETA 03:47:53\n",
      "2021-06-29 21:48:30 [INFO]\t[TRAIN] epoch=11, iter=1850/6000, loss=0.1580, lr=0.000133, batch_cost=3.2932, reader_cost=0.00016, ips=1.2146 samples/sec | ETA 03:47:46\n",
      "2021-06-29 21:49:03 [INFO]\t[TRAIN] epoch=11, iter=1860/6000, loss=0.1631, lr=0.000126, batch_cost=3.2991, reader_cost=0.00019, ips=1.2125 samples/sec | ETA 03:47:38\n",
      "2021-06-29 21:49:36 [INFO]\t[TRAIN] epoch=11, iter=1870/6000, loss=0.1901, lr=0.000119, batch_cost=3.2981, reader_cost=0.00014, ips=1.2128 samples/sec | ETA 03:47:01\n",
      "2021-06-29 21:50:09 [INFO]\t[TRAIN] epoch=11, iter=1880/6000, loss=0.1775, lr=0.000112, batch_cost=3.3098, reader_cost=0.00015, ips=1.2085 samples/sec | ETA 03:47:16\n",
      "2021-06-29 21:50:42 [INFO]\t[TRAIN] epoch=11, iter=1890/6000, loss=0.1822, lr=0.000104, batch_cost=3.2888, reader_cost=0.00015, ips=1.2162 samples/sec | ETA 03:45:17\n",
      "2021-06-29 21:51:16 [INFO]\t[TRAIN] epoch=11, iter=1900/6000, loss=0.1620, lr=0.000097, batch_cost=3.3396, reader_cost=0.00017, ips=1.1977 samples/sec | ETA 03:48:12\n",
      "2021-06-29 21:51:49 [INFO]\t[TRAIN] epoch=11, iter=1910/6000, loss=0.1829, lr=0.000089, batch_cost=3.3296, reader_cost=0.00014, ips=1.2013 samples/sec | ETA 03:46:58\n",
      "2021-06-29 21:52:22 [INFO]\t[TRAIN] epoch=11, iter=1920/6000, loss=0.2023, lr=0.000082, batch_cost=3.3110, reader_cost=0.00019, ips=1.2081 samples/sec | ETA 03:45:08\n",
      "2021-06-29 21:52:55 [INFO]\t[TRAIN] epoch=11, iter=1930/6000, loss=0.1481, lr=0.000074, batch_cost=3.3037, reader_cost=0.00014, ips=1.2108 samples/sec | ETA 03:44:06\n",
      "2021-06-29 21:53:28 [INFO]\t[TRAIN] epoch=11, iter=1940/6000, loss=0.1716, lr=0.000066, batch_cost=3.3045, reader_cost=0.00015, ips=1.2105 samples/sec | ETA 03:43:36\n",
      "2021-06-29 21:54:01 [INFO]\t[TRAIN] epoch=11, iter=1950/6000, loss=0.1565, lr=0.000058, batch_cost=3.3098, reader_cost=0.00021, ips=1.2085 samples/sec | ETA 03:43:24\n",
      "2021-06-29 21:54:34 [INFO]\t[TRAIN] epoch=11, iter=1960/6000, loss=0.1686, lr=0.000050, batch_cost=3.2954, reader_cost=0.00015, ips=1.2138 samples/sec | ETA 03:41:53\n",
      "2021-06-29 21:55:07 [INFO]\t[TRAIN] epoch=11, iter=1970/6000, loss=0.2469, lr=0.000042, batch_cost=3.3001, reader_cost=0.00015, ips=1.2121 samples/sec | ETA 03:41:39\n",
      "2021-06-29 21:55:40 [INFO]\t[TRAIN] epoch=11, iter=1980/6000, loss=0.2289, lr=0.000033, batch_cost=3.2577, reader_cost=0.00018, ips=1.2279 samples/sec | ETA 03:38:15\n",
      "2021-06-29 21:56:13 [INFO]\t[TRAIN] epoch=12, iter=1990/6000, loss=0.1537, lr=0.000024, batch_cost=3.3782, reader_cost=0.08463, ips=1.1841 samples/sec | ETA 03:45:46\n",
      "2021-06-29 21:56:46 [INFO]\t[TRAIN] epoch=12, iter=2000/6000, loss=0.1987, lr=0.000014, batch_cost=3.3027, reader_cost=0.00015, ips=1.2111 samples/sec | ETA 03:40:10\n",
      "2021-06-29 21:56:46 [INFO]\tStart evaluating (total_samples=80, total_iters=80)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 24s 298ms/step - batch_cost: 0.2966 - reader cost: 0.070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-29 21:57:10 [INFO]\t[EVAL] #Images=80 mIoU=0.7835 Acc=0.9889 Kappa=0.7273 \n",
      "2021-06-29 21:57:10 [INFO]\t[EVAL] Class IoU: \n",
      "[0.5783 0.9887]\n",
      "2021-06-29 21:57:10 [INFO]\t[EVAL] Class Acc: \n",
      "[0.627  0.9979]\n",
      "2021-06-29 21:57:17 [INFO]\t[EVAL] The model with the best validation mIoU (0.7835) was saved at iter 1400.\n",
      "2021-06-29 21:57:50 [INFO]\t[TRAIN] epoch=12, iter=2010/6000, loss=0.1854, lr=0.000013, batch_cost=3.3027, reader_cost=0.00015, ips=1.2111 samples/sec | ETA 03:39:37\n",
      "2021-06-29 21:58:23 [INFO]\t[TRAIN] epoch=12, iter=2020/6000, loss=0.1748, lr=0.000013, batch_cost=3.2994, reader_cost=0.00015, ips=1.2123 samples/sec | ETA 03:38:51\n",
      "2021-06-29 21:58:56 [INFO]\t[TRAIN] epoch=12, iter=2030/6000, loss=0.1959, lr=0.000013, batch_cost=3.3040, reader_cost=0.00016, ips=1.2106 samples/sec | ETA 03:38:37\n",
      "2021-06-29 21:59:29 [INFO]\t[TRAIN] epoch=12, iter=2040/6000, loss=0.1416, lr=0.000013, batch_cost=3.2833, reader_cost=0.00016, ips=1.2183 samples/sec | ETA 03:36:42\n",
      "2021-06-29 22:00:02 [INFO]\t[TRAIN] epoch=12, iter=2050/6000, loss=0.1968, lr=0.000013, batch_cost=3.2994, reader_cost=0.00016, ips=1.2123 samples/sec | ETA 03:37:12\n",
      "2021-06-29 22:00:35 [INFO]\t[TRAIN] epoch=12, iter=2060/6000, loss=0.2131, lr=0.000013, batch_cost=3.2958, reader_cost=0.00019, ips=1.2137 samples/sec | ETA 03:36:25\n",
      "2021-06-29 22:01:08 [INFO]\t[TRAIN] epoch=12, iter=2070/6000, loss=0.1187, lr=0.000013, batch_cost=3.3095, reader_cost=0.00015, ips=1.2086 samples/sec | ETA 03:36:46\n",
      "2021-06-29 22:01:41 [INFO]\t[TRAIN] epoch=12, iter=2080/6000, loss=0.1597, lr=0.000013, batch_cost=3.2852, reader_cost=0.00015, ips=1.2176 samples/sec | ETA 03:34:37\n",
      "2021-06-29 22:02:13 [INFO]\t[TRAIN] epoch=12, iter=2090/6000, loss=0.1714, lr=0.000013, batch_cost=3.2636, reader_cost=0.00016, ips=1.2256 samples/sec | ETA 03:32:40\n",
      "2021-06-29 22:02:46 [INFO]\t[TRAIN] epoch=12, iter=2100/6000, loss=0.1700, lr=0.000013, batch_cost=3.3053, reader_cost=0.00019, ips=1.2102 samples/sec | ETA 03:34:50\n",
      "2021-06-29 22:03:19 [INFO]\t[TRAIN] epoch=12, iter=2110/6000, loss=0.1716, lr=0.000013, batch_cost=3.2985, reader_cost=0.00014, ips=1.2127 samples/sec | ETA 03:33:51\n",
      "2021-06-29 22:03:52 [INFO]\t[TRAIN] epoch=12, iter=2120/6000, loss=0.2400, lr=0.000013, batch_cost=3.3099, reader_cost=0.00019, ips=1.2085 samples/sec | ETA 03:34:02\n",
      "2021-06-29 22:04:25 [INFO]\t[TRAIN] epoch=12, iter=2130/6000, loss=0.2064, lr=0.000013, batch_cost=3.2913, reader_cost=0.00017, ips=1.2153 samples/sec | ETA 03:32:17\n",
      "2021-06-29 22:04:58 [INFO]\t[TRAIN] epoch=12, iter=2140/6000, loss=0.1605, lr=0.000013, batch_cost=3.2800, reader_cost=0.00016, ips=1.2195 samples/sec | ETA 03:31:00\n",
      "2021-06-29 22:05:31 [INFO]\t[TRAIN] epoch=12, iter=2150/6000, loss=0.2151, lr=0.000013, batch_cost=3.2879, reader_cost=0.00016, ips=1.2166 samples/sec | ETA 03:30:58\n",
      "2021-06-29 22:06:04 [INFO]\t[TRAIN] epoch=12, iter=2160/6000, loss=0.1596, lr=0.000013, batch_cost=3.2814, reader_cost=0.00015, ips=1.2190 samples/sec | ETA 03:30:00\n",
      "2021-06-29 22:06:38 [INFO]\t[TRAIN] epoch=13, iter=2170/6000, loss=0.1271, lr=0.000013, batch_cost=3.3798, reader_cost=0.08091, ips=1.1835 samples/sec | ETA 03:35:44\n",
      "2021-06-29 22:07:11 [INFO]\t[TRAIN] epoch=13, iter=2180/6000, loss=0.2221, lr=0.000013, batch_cost=3.2973, reader_cost=0.00017, ips=1.2131 samples/sec | ETA 03:29:55\n",
      "2021-06-29 22:07:43 [INFO]\t[TRAIN] epoch=13, iter=2190/6000, loss=0.1488, lr=0.000013, batch_cost=3.2976, reader_cost=0.00017, ips=1.2130 samples/sec | ETA 03:29:23\n",
      "2021-06-29 22:08:16 [INFO]\t[TRAIN] epoch=13, iter=2200/6000, loss=0.1963, lr=0.000013, batch_cost=3.2919, reader_cost=0.00015, ips=1.2151 samples/sec | ETA 03:28:29\n",
      "2021-06-29 22:08:16 [INFO]\tStart evaluating (total_samples=80, total_iters=80)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 23s 291ms/step - batch_cost: 0.2893 - reader cost: 0.06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-29 22:08:40 [INFO]\t[EVAL] #Images=80 mIoU=0.7685 Acc=0.9873 Kappa=0.7034 \n",
      "2021-06-29 22:08:40 [INFO]\t[EVAL] Class IoU: \n",
      "[0.5499 0.9871]\n",
      "2021-06-29 22:08:40 [INFO]\t[EVAL] Class Acc: \n",
      "[0.5867 0.9982]\n",
      "2021-06-29 22:08:45 [INFO]\t[EVAL] The model with the best validation mIoU (0.7835) was saved at iter 1400.\n",
      "2021-06-29 22:09:18 [INFO]\t[TRAIN] epoch=13, iter=2210/6000, loss=0.1747, lr=0.000013, batch_cost=3.3015, reader_cost=0.00016, ips=1.2116 samples/sec | ETA 03:28:32\n",
      "2021-06-29 22:09:51 [INFO]\t[TRAIN] epoch=13, iter=2220/6000, loss=0.1404, lr=0.000013, batch_cost=3.3041, reader_cost=0.00016, ips=1.2106 samples/sec | ETA 03:28:09\n",
      "2021-06-29 22:10:24 [INFO]\t[TRAIN] epoch=13, iter=2230/6000, loss=0.2503, lr=0.000013, batch_cost=3.2971, reader_cost=0.00018, ips=1.2132 samples/sec | ETA 03:27:10\n",
      "2021-06-29 22:10:57 [INFO]\t[TRAIN] epoch=13, iter=2240/6000, loss=0.1657, lr=0.000013, batch_cost=3.2930, reader_cost=0.00014, ips=1.2147 samples/sec | ETA 03:26:21\n",
      "2021-06-29 22:11:30 [INFO]\t[TRAIN] epoch=13, iter=2250/6000, loss=0.1508, lr=0.000013, batch_cost=3.2977, reader_cost=0.00017, ips=1.2130 samples/sec | ETA 03:26:06\n",
      "2021-06-29 22:12:03 [INFO]\t[TRAIN] epoch=13, iter=2260/6000, loss=0.1646, lr=0.000013, batch_cost=3.2926, reader_cost=0.00016, ips=1.2149 samples/sec | ETA 03:25:14\n",
      "2021-06-29 22:12:36 [INFO]\t[TRAIN] epoch=13, iter=2270/6000, loss=0.1308, lr=0.000013, batch_cost=3.2878, reader_cost=0.00018, ips=1.2166 samples/sec | ETA 03:24:23\n",
      "2021-06-29 22:13:09 [INFO]\t[TRAIN] epoch=13, iter=2280/6000, loss=0.1970, lr=0.000013, batch_cost=3.2929, reader_cost=0.00016, ips=1.2147 samples/sec | ETA 03:24:09\n",
      "2021-06-29 22:13:42 [INFO]\t[TRAIN] epoch=13, iter=2290/6000, loss=0.1338, lr=0.000013, batch_cost=3.2825, reader_cost=0.00018, ips=1.2186 samples/sec | ETA 03:22:58\n",
      "2021-06-29 22:14:15 [INFO]\t[TRAIN] epoch=13, iter=2300/6000, loss=0.2354, lr=0.000013, batch_cost=3.3046, reader_cost=0.00015, ips=1.2104 samples/sec | ETA 03:23:47\n",
      "2021-06-29 22:14:48 [INFO]\t[TRAIN] epoch=13, iter=2310/6000, loss=0.1599, lr=0.000013, batch_cost=3.3095, reader_cost=0.00015, ips=1.2086 samples/sec | ETA 03:23:32\n",
      "2021-06-29 22:15:21 [INFO]\t[TRAIN] epoch=13, iter=2320/6000, loss=0.1467, lr=0.000013, batch_cost=3.3196, reader_cost=0.00016, ips=1.2050 samples/sec | ETA 03:23:35\n",
      "2021-06-29 22:15:54 [INFO]\t[TRAIN] epoch=13, iter=2330/6000, loss=0.1958, lr=0.000013, batch_cost=3.2955, reader_cost=0.00014, ips=1.2138 samples/sec | ETA 03:21:34\n",
      "2021-06-29 22:16:27 [INFO]\t[TRAIN] epoch=13, iter=2340/6000, loss=0.1913, lr=0.000013, batch_cost=3.2646, reader_cost=0.00015, ips=1.2252 samples/sec | ETA 03:19:08\n",
      "2021-06-29 22:17:01 [INFO]\t[TRAIN] epoch=14, iter=2350/6000, loss=0.1684, lr=0.000013, batch_cost=3.3834, reader_cost=0.05252, ips=1.1823 samples/sec | ETA 03:25:49\n",
      "2021-06-29 22:17:34 [INFO]\t[TRAIN] epoch=14, iter=2360/6000, loss=0.1733, lr=0.000013, batch_cost=3.3109, reader_cost=0.00015, ips=1.2081 samples/sec | ETA 03:20:51\n",
      "2021-06-29 22:18:07 [INFO]\t[TRAIN] epoch=14, iter=2370/6000, loss=0.1330, lr=0.000013, batch_cost=3.3139, reader_cost=0.00015, ips=1.2071 samples/sec | ETA 03:20:29\n",
      "2021-06-29 22:18:40 [INFO]\t[TRAIN] epoch=14, iter=2380/6000, loss=0.1541, lr=0.000013, batch_cost=3.2955, reader_cost=0.00014, ips=1.2138 samples/sec | ETA 03:18:49\n",
      "2021-06-29 22:19:13 [INFO]\t[TRAIN] epoch=14, iter=2390/6000, loss=0.1897, lr=0.000013, batch_cost=3.2831, reader_cost=0.00018, ips=1.2184 samples/sec | ETA 03:17:31\n",
      "2021-06-29 22:19:46 [INFO]\t[TRAIN] epoch=14, iter=2400/6000, loss=0.1795, lr=0.000013, batch_cost=3.3117, reader_cost=0.00014, ips=1.2078 samples/sec | ETA 03:18:42\n",
      "2021-06-29 22:19:46 [INFO]\tStart evaluating (total_samples=80, total_iters=80)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 24s 302ms/step - batch_cost: 0.3011 - reader cost: 0.07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-29 22:20:10 [INFO]\t[EVAL] #Images=80 mIoU=0.7802 Acc=0.9885 Kappa=0.7222 \n",
      "2021-06-29 22:20:10 [INFO]\t[EVAL] Class IoU: \n",
      "[0.5721 0.9883]\n",
      "2021-06-29 22:20:10 [INFO]\t[EVAL] Class Acc: \n",
      "[0.6158 0.998 ]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d87cc6050484>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m                      \u001b[0;31m# 多线程关闭(0)--在平台上开启可能会断掉\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m                      \u001b[0;31m# 损失字典\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     use_vdl=True)                       # 是否记录训练参数\n\u001b[0m",
      "\u001b[0;32m~/PaddleSeg/paddleseg/core/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataset, val_dataset, optimizer, save_dir, iters, batch_size, resume_model, save_interval, log_iters, num_workers, use_vdl, losses, keep_checkpoint_max)\u001b[0m\n\u001b[1;32m    217\u001b[0m                             os.path.join(current_save_dir, 'model.pdparams'))\n\u001b[1;32m    218\u001b[0m                 paddle.save(optimizer.state_dict(),\n\u001b[0;32m--> 219\u001b[0;31m                             os.path.join(current_save_dir, 'model.pdopt'))\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0msave_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_save_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_models\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mkeep_checkpoint_max\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/framework/io.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, path, pickle_protocol)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m             \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(\r\n",
    "    model=model,                        # 创建的模型\r\n",
    "    train_dataset=train_dataset,        # 训练数据集\r\n",
    "    val_dataset=eval_dataset,           # 验证数据集\r\n",
    "    optimizer=optimizer,                # 优化器\r\n",
    "    save_dir='output',                  # 保存路径--不必该，否则后边程序也需要修正\r\n",
    "    iters=6000,                         # 训练迭代次数（这里不是轮次）\r\n",
    "    batch_size=4,                       # 批大小\r\n",
    "    save_interval=200,                  # 验证+保存的迭代周期\r\n",
    "    log_iters=10,                       # 日志输出的迭代周期\r\n",
    "    num_workers=0,                      # 多线程关闭(0)--在平台上开启可能会断掉\r\n",
    "    losses=losses,                      # 损失字典\r\n",
    "    use_vdl=True)                       # 是否记录训练参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 5.开始预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "预测的配置略微不同，需要读取`test_list.txt`中的文件进入list中，然后传入list以及Image_dir进行预测\n",
    "\n",
    "> 前面的训练与验证是通过给dir，自动搜寻，这里不一样，要注意一下哦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_list = []\r\n",
    "test_root = 'data'      # 之前划分数据图像保存的根路径\r\n",
    "with open('data/test_list.txt') as f: \r\n",
    "    for i in f.readlines():\r\n",
    "        test_list.append(os.path.join(test_root, i[:-1]))   # 逐行写入，-1是为了去掉 \\n\r\n",
    "\r\n",
    "# 预测的transform也略有不同，前边时list，这里需要严格的传入transform格式\r\n",
    "# 利用Compose实现多处理\r\n",
    "transforms = T.Compose([\r\n",
    "    T.Resize(target_size=(800, 800)),\r\n",
    "    T.Normalize()\r\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "使用`predict`接口进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-29 16:08:04 [INFO]\tLoading pretrained model from output/best_model/model.pdparams\n",
      "2021-06-29 16:08:06 [INFO]\tThere are 312/312 variables loaded into EMANet.\n",
      "2021-06-29 16:08:06 [INFO]\tStart to predict...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 215s 536ms/ste\n"
     ]
    }
   ],
   "source": [
    "predict(\r\n",
    "        model,                                           # 创建的模型\r\n",
    "        model_path='output/best_model/model.pdparams',   # 模型参数\r\n",
    "        transforms=transforms,                           # 数据处理方式--尽量避免高斯那些操作，在这里效果不好\r\n",
    "        image_list=test_list,                            # 上边生成的图片list\r\n",
    "        image_dir=test_root,                             # 图片保存的形式--保证预测结果保存在同名的结构中，但不是在test_root目录下，而是output/results中\r\n",
    "        save_dir='output/results'                        # 保存路径——PaddleSeg/output/results/pseudo_color_prediction：为真实预测结果\r\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 6.后处理并生成提交文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio\n",
      "————开始提交结果前的后处理————\n",
      "100%|█████████████████████████████████████████| 400/400 [00:25<00:00, 15.81it/s]\n",
      "后处理完成(cost: 25.30918002128601 s)！\n"
     ]
    }
   ],
   "source": [
    "%cd /home/aistudio\r\n",
    "!python utils/post_process.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: Disc_Segmentation/ (stored 0%)\n",
      "updating: Disc_Segmentation/T0295.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0375.png (deflated 88%)\n",
      "updating: Disc_Segmentation/T0089.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0312.png (deflated 98%)\n",
      "updating: Disc_Segmentation/T0262.png (deflated 88%)\n",
      "updating: Disc_Segmentation/T0331.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0379.png (deflated 98%)\n",
      "updating: Disc_Segmentation/T0290.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0223.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0289.png (deflated 89%)\n",
      "updating: Disc_Segmentation/T0087.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0386.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0179.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0081.png (deflated 73%)\n",
      "updating: Disc_Segmentation/T0305.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0275.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0368.png (deflated 98%)\n",
      "updating: Disc_Segmentation/T0128.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0278.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0194.png (deflated 90%)\n",
      "updating: Disc_Segmentation/T0385.png (deflated 83%)\n",
      "updating: Disc_Segmentation/T0342.png (deflated 83%)\n",
      "updating: Disc_Segmentation/T0310.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0079.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0246.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0256.png (deflated 70%)\n",
      "updating: Disc_Segmentation/T0095.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0105.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0218.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0099.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0270.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0229.png (deflated 83%)\n",
      "updating: Disc_Segmentation/T0320.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0106.png (deflated 74%)\n",
      "updating: Disc_Segmentation/T0391.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0225.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0298.png (deflated 82%)\n",
      "updating: Disc_Segmentation/T0164.png (deflated 83%)\n",
      "updating: Disc_Segmentation/T0344.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0058.png (deflated 98%)\n",
      "updating: Disc_Segmentation/T0241.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0365.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0151.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0109.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0253.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0322.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0036.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0033.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0213.png (deflated 98%)\n",
      "updating: Disc_Segmentation/T0144.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0011.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0016.png (deflated 83%)\n",
      "updating: Disc_Segmentation/T0243.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0112.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0168.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0389.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0134.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0252.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0340.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0255.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0352.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0166.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0254.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0205.png (deflated 75%)\n",
      "updating: Disc_Segmentation/T0044.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0026.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0122.png (deflated 91%)\n",
      "updating: Disc_Segmentation/T0091.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0294.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0351.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0069.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0339.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0353.png (deflated 93%)\n",
      "updating: Disc_Segmentation/T0157.png (deflated 83%)\n",
      "updating: Disc_Segmentation/T0378.png (deflated 88%)\n",
      "updating: Disc_Segmentation/T0067.png (deflated 97%)\n",
      "updating: Disc_Segmentation/T0209.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0335.png (deflated 83%)\n",
      "updating: Disc_Segmentation/T0039.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0274.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0146.png (deflated 89%)\n",
      "updating: Disc_Segmentation/T0007.png (deflated 82%)\n",
      "updating: Disc_Segmentation/T0064.png (deflated 97%)\n",
      "updating: Disc_Segmentation/T0244.png (deflated 91%)\n",
      "updating: Disc_Segmentation/T0272.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0284.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0171.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0059.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0094.png (deflated 88%)\n",
      "updating: Disc_Segmentation/T0324.png (deflated 97%)\n",
      "updating: Disc_Segmentation/T0333.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0023.png (deflated 71%)\n",
      "updating: Disc_Segmentation/T0239.png (deflated 74%)\n",
      "updating: Disc_Segmentation/T0043.png (deflated 98%)\n",
      "updating: Disc_Segmentation/T0020.png (deflated 78%)\n",
      "updating: Disc_Segmentation/T0136.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0268.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0005.png (deflated 69%)\n",
      "updating: Disc_Segmentation/T0142.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0103.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0015.png (deflated 88%)\n",
      "updating: Disc_Segmentation/T0192.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0070.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0041.png (deflated 75%)\n",
      "updating: Disc_Segmentation/T0286.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0117.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0381.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0178.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0063.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0302.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0140.png (deflated 76%)\n",
      "updating: Disc_Segmentation/T0037.png (deflated 98%)\n",
      "updating: Disc_Segmentation/T0357.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0215.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0169.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0240.png (deflated 82%)\n",
      "updating: Disc_Segmentation/T0012.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0184.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0006.png (deflated 83%)\n",
      "updating: Disc_Segmentation/T0008.png (deflated 90%)\n",
      "updating: Disc_Segmentation/T0035.png (deflated 71%)\n",
      "updating: Disc_Segmentation/T0155.png (deflated 83%)\n",
      "updating: Disc_Segmentation/T0080.png (deflated 74%)\n",
      "updating: Disc_Segmentation/T0154.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0090.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0309.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0321.png (deflated 98%)\n",
      "updating: Disc_Segmentation/T0316.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0260.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0191.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0193.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0055.png (deflated 97%)\n",
      "updating: Disc_Segmentation/T0273.png (deflated 98%)\n",
      "updating: Disc_Segmentation/T0264.png (deflated 73%)\n",
      "updating: Disc_Segmentation/T0174.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0327.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0291.png (deflated 82%)\n",
      "updating: Disc_Segmentation/T0394.png (deflated 93%)\n",
      "updating: Disc_Segmentation/T0196.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0261.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0293.png (deflated 96%)\n",
      "updating: Disc_Segmentation/T0051.png (deflated 73%)\n",
      "updating: Disc_Segmentation/T0297.png (deflated 75%)\n",
      "updating: Disc_Segmentation/T0361.png (deflated 83%)\n",
      "updating: Disc_Segmentation/T0366.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0093.png (deflated 98%)\n",
      "updating: Disc_Segmentation/T0347.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0029.png (deflated 98%)\n",
      "updating: Disc_Segmentation/T0118.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0190.png (deflated 98%)\n",
      "updating: Disc_Segmentation/T0126.png (deflated 83%)\n",
      "updating: Disc_Segmentation/T0337.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0110.png (deflated 98%)\n",
      "updating: Disc_Segmentation/T0124.png (deflated 71%)\n",
      "updating: Disc_Segmentation/T0189.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0182.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0049.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0185.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0004.png (deflated 88%)\n",
      "updating: Disc_Segmentation/T0242.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0285.png (deflated 83%)\n",
      "updating: Disc_Segmentation/T0332.png (deflated 68%)\n",
      "updating: Disc_Segmentation/T0053.png (deflated 75%)\n",
      "updating: Disc_Segmentation/T0071.png (deflated 88%)\n",
      "updating: Disc_Segmentation/T0208.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0300.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0231.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0382.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0296.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0075.png (deflated 98%)\n",
      "updating: Disc_Segmentation/T0129.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0042.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0017.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0248.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0038.png (deflated 74%)\n",
      "updating: Disc_Segmentation/T0101.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0308.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0176.png (deflated 91%)\n",
      "updating: Disc_Segmentation/T0107.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0123.png (deflated 82%)\n",
      "updating: Disc_Segmentation/T0227.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0334.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0343.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0120.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0292.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0269.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0156.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0014.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0195.png (deflated 98%)\n",
      "updating: Disc_Segmentation/T0003.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0304.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0114.png (deflated 89%)\n",
      "updating: Disc_Segmentation/T0150.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0355.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0141.png (deflated 75%)\n",
      "updating: Disc_Segmentation/T0393.png (deflated 89%)\n",
      "updating: Disc_Segmentation/T0358.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0180.png (deflated 89%)\n",
      "updating: Disc_Segmentation/T0283.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0220.png (deflated 91%)\n",
      "updating: Disc_Segmentation/T0219.png (deflated 80%)\n",
      "updating: Disc_Segmentation/T0303.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0204.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0187.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0002.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0121.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0139.png (deflated 97%)\n",
      "updating: Disc_Segmentation/T0315.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0314.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0199.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0319.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0048.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0201.png (deflated 97%)\n",
      "updating: Disc_Segmentation/T0349.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0161.png (deflated 83%)\n",
      "updating: Disc_Segmentation/T0132.png (deflated 76%)\n",
      "updating: Disc_Segmentation/T0232.png (deflated 75%)\n",
      "updating: Disc_Segmentation/T0200.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0028.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0266.png (deflated 83%)\n",
      "updating: Disc_Segmentation/T0263.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0238.png (deflated 98%)\n",
      "updating: Disc_Segmentation/T0317.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0170.png (deflated 97%)\n",
      "updating: Disc_Segmentation/T0113.png (deflated 98%)\n",
      "updating: Disc_Segmentation/T0279.png (deflated 98%)\n",
      "updating: Disc_Segmentation/T0177.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0210.png (deflated 98%)\n",
      "updating: Disc_Segmentation/T0383.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0022.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0018.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0259.png (deflated 83%)\n",
      "updating: Disc_Segmentation/T0111.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0216.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0370.png (deflated 80%)\n",
      "updating: Disc_Segmentation/T0346.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0369.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0323.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0277.png (deflated 82%)\n",
      "updating: Disc_Segmentation/T0251.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0145.png (deflated 90%)\n",
      "updating: Disc_Segmentation/T0341.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0258.png (deflated 83%)\n",
      "updating: Disc_Segmentation/T0362.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0173.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0288.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0061.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0249.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0085.png (deflated 98%)\n",
      "updating: Disc_Segmentation/T0119.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0376.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0056.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0153.png (deflated 73%)\n",
      "updating: Disc_Segmentation/T0138.png (deflated 83%)\n",
      "updating: Disc_Segmentation/T0047.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0374.png (deflated 89%)\n",
      "updating: Disc_Segmentation/T0207.png (deflated 98%)\n",
      "updating: Disc_Segmentation/T0040.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0013.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0250.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0371.png (deflated 79%)\n",
      "updating: Disc_Segmentation/T0159.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0326.png (deflated 91%)\n",
      "updating: Disc_Segmentation/T0032.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0135.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0247.png (deflated 83%)\n",
      "updating: Disc_Segmentation/T0147.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0086.png (deflated 98%)\n",
      "updating: Disc_Segmentation/T0054.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0299.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0224.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0125.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0384.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0360.png (deflated 98%)\n",
      "updating: Disc_Segmentation/T0373.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0092.png (deflated 96%)\n",
      "updating: Disc_Segmentation/T0350.png (deflated 83%)\n",
      "updating: Disc_Segmentation/T0046.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0237.png (deflated 98%)\n",
      "updating: Disc_Segmentation/T0009.png (deflated 83%)\n",
      "updating: Disc_Segmentation/T0197.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0062.png (deflated 98%)\n",
      "updating: Disc_Segmentation/T0222.png (deflated 82%)\n",
      "updating: Disc_Segmentation/T0183.png (deflated 83%)\n",
      "updating: Disc_Segmentation/T0165.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0282.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0397.png (deflated 90%)\n",
      "updating: Disc_Segmentation/T0307.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0031.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0363.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0338.png (deflated 88%)\n",
      "updating: Disc_Segmentation/T0030.png (deflated 91%)\n",
      "updating: Disc_Segmentation/T0396.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0025.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0100.png (deflated 98%)\n",
      "updating: Disc_Segmentation/T0211.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0021.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0050.png (deflated 88%)\n",
      "updating: Disc_Segmentation/T0181.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0354.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0143.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0395.png (deflated 91%)\n",
      "updating: Disc_Segmentation/T0163.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0318.png (deflated 82%)\n",
      "updating: Disc_Segmentation/T0280.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0388.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0271.png (deflated 73%)\n",
      "updating: Disc_Segmentation/T0377.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0162.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0175.png (deflated 83%)\n",
      "updating: Disc_Segmentation/T0387.png (deflated 98%)\n",
      "updating: Disc_Segmentation/T0077.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0306.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0160.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0083.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0133.png (deflated 98%)\n",
      "updating: Disc_Segmentation/T0380.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0202.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0076.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0281.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0356.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0392.png (deflated 76%)\n",
      "updating: Disc_Segmentation/T0127.png (deflated 82%)\n",
      "updating: Disc_Segmentation/T0198.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0214.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0131.png (deflated 77%)\n",
      "updating: Disc_Segmentation/T0098.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0226.png (deflated 88%)\n",
      "updating: Disc_Segmentation/T0359.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0345.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0367.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0082.png (deflated 97%)\n",
      "updating: Disc_Segmentation/T0104.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0060.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0217.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0400.png (deflated 74%)\n",
      "updating: Disc_Segmentation/T0348.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0024.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0137.png (deflated 78%)\n",
      "updating: Disc_Segmentation/T0045.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0073.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0148.png (deflated 83%)\n",
      "updating: Disc_Segmentation/T0001.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0167.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0149.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0206.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0019.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0078.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0057.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0311.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0188.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0152.png (deflated 75%)\n",
      "updating: Disc_Segmentation/T0096.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0235.png (deflated 98%)\n",
      "updating: Disc_Segmentation/T0027.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0336.png (deflated 88%)\n",
      "updating: Disc_Segmentation/T0390.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0325.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0115.png (deflated 88%)\n",
      "updating: Disc_Segmentation/T0186.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0102.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0236.png (deflated 76%)\n",
      "updating: Disc_Segmentation/T0233.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0313.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0230.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0330.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0228.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0010.png (deflated 83%)\n",
      "updating: Disc_Segmentation/T0372.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0234.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0203.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0097.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0265.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0052.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0068.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0276.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0065.png (deflated 75%)\n",
      "updating: Disc_Segmentation/T0212.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0172.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0074.png (deflated 83%)\n",
      "updating: Disc_Segmentation/T0245.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0108.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0301.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0364.png (deflated 75%)\n",
      "updating: Disc_Segmentation/T0116.png (deflated 96%)\n",
      "updating: Disc_Segmentation/T0328.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0287.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0399.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0329.png (deflated 98%)\n",
      "updating: Disc_Segmentation/T0257.png (deflated 84%)\n",
      "updating: Disc_Segmentation/T0088.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0130.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0267.png (deflated 85%)\n",
      "updating: Disc_Segmentation/T0072.png (deflated 83%)\n",
      "updating: Disc_Segmentation/T0066.png (deflated 87%)\n",
      "updating: Disc_Segmentation/T0034.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0158.png (deflated 88%)\n",
      "updating: Disc_Segmentation/T0398.png (deflated 88%)\n",
      "updating: Disc_Segmentation/T0221.png (deflated 86%)\n",
      "updating: Disc_Segmentation/T0084.png (deflated 83%)\n"
     ]
    }
   ],
   "source": [
    "# 复制文件到最顶层目录\r\n",
    "!cp -r PaddleSeg/output/results/pseudo_color_prediction/Image/ Disc_Segmentation\r\n",
    "# 压缩文件\r\n",
    "!zip -r Disc_Segmentation.zip Disc_Segmentation\r\n",
    "# 删除复制的文件\r\n",
    "!rm -rf Disc_Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **六、结果分析**\n",
    "\n",
    "眼底分割：\n",
    "\n",
    "680x680，lr=0.001：0.899\n",
    "\n",
    "800x800，lr=0.00125，垂直翻转：0.902\n",
    "\n",
    "800x800,lr=0.00125,垂直翻转：**0.93276**\n",
    "\n",
    "800x800，lr=0.01，垂直翻转，：0.92813\n",
    "\n",
    "800x800，lr=0.001：0.88579\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "其它一些清理步骤选择性使用即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 删除zip的文件--丢失提交结果，需重新后处理生成\r\n",
    "# !rm -rf Disc_Segmentation.zip\r\n",
    "# 删除预测结果--丢失预测结果，需重新预测\r\n",
    "# !rm -rf PaddleSeg/output/results\r\n",
    "# 删除output文件夹--丢失模型参数，需重新训练\r\n",
    "# !rm -rf PaddleSeg/output\r\n",
    "# 删除data文件夹--数据将丢失，需要重新解压，划分，预处置\r\n",
    "# !rm -rf PaddleSeg/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 七、总结以及建议\n",
    "\n",
    "\n",
    "1.使用不同的网络模型，例如注意力模型或者经典的unet模型\n",
    "\n",
    "2.提高图片尺寸，相应的可以提高预测精度\n",
    "\n",
    "3.传统的数据增强是增分的稳定点，需要多加尝试\n",
    "\n",
    "4.可以进一步尝试不同的优化器和学习率衰减函数结合\n",
    "\n",
    "5.多损失结构，不同的ccoef，针对赛题的特殊损失等\n",
    "\n",
    "6.尝试对Unet添加注意力模块，修改参数，或者调整不同的backbone与indices组合\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
